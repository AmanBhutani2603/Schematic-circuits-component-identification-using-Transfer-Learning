{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet - 50  Batch Size - ML.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"MfZr5GpLfV8M"},"source":["### Mounting drive on Colab"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1017283,"status":"ok","timestamp":1649245815905,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"},"user_tz":-330},"id":"efjsRr4LAtas","outputId":"8f954039-b31f-4995-de2b-e9428490a914"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount = True)"]},{"cell_type":"markdown","metadata":{"id":"yYQAlX3dFz2E"},"source":["###Libraries"]},{"cell_type":"code","source":["!pip install tensorflow_addons"],"metadata":{"id":"qrxwEMoRxRKn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649245820278,"user_tz":-330,"elapsed":4384,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}},"outputId":"87b35b8a-e6be-47be-d7cd-1b98dd4823f9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.16.1\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"tBQUozfKF1sR","executionInfo":{"status":"ok","timestamp":1649245824249,"user_tz":-330,"elapsed":3992,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}}},"outputs":[],"source":["import os\n","import cv2\n","import os\n","import h5py\n","import numpy as np\n","import pickle\n","from tqdm import tqdm\n","from PIL import Image\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow_addons.metrics import HammingLoss\n","from tensorflow_addons.metrics import F1Score\n","os.chdir('/gdrive/My Drive/')\n","from numpy import savez_compressed\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageEnhance\n","import tensorflow_datasets as tfds\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras import layers, models\n","import tensorflow.keras as keras\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from keras.models import Sequential, load_model\n","from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model"]},{"cell_type":"markdown","metadata":{"id":"lkUoKLs_R-97"},"source":["## Effects of changing Batch Size\n","\n","\n","\n","---\n","\n","\n","Experimental Setup:\n","\n","Following are the details of the experimental setup for the above-mentioned experiment:\n","\n","Model used: ResNet50\n","\n","Note: In order to make sure even though a range of batch sizes were used for this experiment all the models were trained for the same number of steps the epochs were changed accordingly.\n","\n","For Ex: \n","\n","        Batch sizes used: [12, 24, 36, 48, 60, 72, 84, 96, 108, 120]\n","\n","        Number of steps: 2000\n","\n","        Given the relationship:\n","\n","        Number of steps = (Dataset Size/ Batch Size) * Number of Epochs\n","\n","        Therefore, if: Dataset Size = 24,000\n","\n","        Batch Size = 12\n","\n","        Number of Steps = 24,000/12 * epochs = 2,000 * epochs\n","\n","        Number of Epochs = 1\n","\n","        Dataset Size = 24,000\n","\n","        Batch Size = 24\n","\n","        Number of Steps = 24,000/24 * epochs = 1000 * epochs\n","\n","        Number of Epochs = 2\n","\n","        Therefore, Epochs: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"]},{"cell_type":"markdown","metadata":{"id":"krhfEtLwdA_S"},"source":["### For ImageNet as a source"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"RcKU925rIgdD","executionInfo":{"status":"ok","timestamp":1649245907873,"user_tz":-330,"elapsed":5505,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}}},"outputs":[],"source":["from tensorflow.keras.applications.resnet50 import ResNet50\n","\n","from timeit import default_timer as timer\n","\n","class TimingCallback(keras.callbacks.Callback):\n","    def __init__(self, logs={}):\n","        self.logs=[]\n","    def on_epoch_begin(self, epoch, logs={}):\n","        self.starttime = timer()\n","    def on_epoch_end(self, epoch, logs={}):\n","        self.logs.append(timer()-self.starttime)\n","\n","cb = TimingCallback()\n","\n","\n","pre_trained_model = ResNet50(input_shape = (96, 96, 3), \n","                                include_top = False, \n","                                weights = None)\n","\n","#for layer in pre_trained_model.layers:\n","#  layer.trainable = False"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"nUNjQNXjJ46g","executionInfo":{"status":"ok","timestamp":1649245907874,"user_tz":-330,"elapsed":7,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}}},"outputs":[],"source":["def compile_model():\n","  from tensorflow.keras.optimizers import RMSprop\n","\n","  # Flatten the output layer to 1 dimension\n","  x = layers.Flatten()(pre_trained_model.output)\n","  # Add a fully connected layer with 2000 hidden units and ReLU activation\n","  x = layers.Dense(2000, activation='relu')(x)\n","  # Add a fully connected layer with 2000 hidden units and ReLU activation\n","  x = layers.Dense(1000, activation='relu')(x)\n","  # Add a fully connected layer with 2000 hidden units and ReLU activation\n","  x = layers.Dense(500, activation='relu')(x)                  \n","  # Add a final softmax layer for classification\n","  x = layers.Dense(15, activation='softmax')(x)           \n","\n","  model = Model( pre_trained_model.input, x) \n","\n","  model.compile(optimizer = RMSprop(lr=0.0001), \n","              loss = 'categorical_crossentropy', \n","              metrics = ['acc', tf.keras.metrics.AUC(), tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), HammingLoss(threshold=0.5, mode='multiclass'), F1Score(num_classes= 15, threshold=0.5)])\n","  return model"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"6EXImFTQWJXQ","executionInfo":{"status":"ok","timestamp":1649245919721,"user_tz":-330,"elapsed":11853,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}}},"outputs":[],"source":["data = np.load('Xtrain.npy', allow_pickle=True)\n","labels = np.load('ytrain.npy', allow_pickle=True)\n","\n","X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size = 0.2, random_state = 42, stratify = labels)\n","X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42, stratify = y_test)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"hMpAHZ-3FJuK","executionInfo":{"status":"ok","timestamp":1649245919722,"user_tz":-330,"elapsed":3,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}}},"outputs":[],"source":["y_train = to_categorical(y_train, 15)\n","y_val = to_categorical(y_val, 15)\n","y_test = to_categorical(y_test, 15)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jzXQVXaAR-jk","outputId":"e7c47377-80b2-40e5-b11b-946ad654b808","executionInfo":{"status":"ok","timestamp":1649246430200,"user_tz":-330,"elapsed":510481,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 12 batch size and for 1 epochs\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["2000/2000 [==============================] - 500s 237ms/step - loss: 2.6981 - acc: 0.1141 - auc: 0.6139 - recall: 0.0070 - precision: 0.2216 - hamming_loss: 0.9930 - f1_score: 0.0134 - val_loss: 2.2624 - val_acc: 0.2190 - val_auc: 0.7908 - val_recall: 0.0270 - val_precision: 0.4551 - val_hamming_loss: 0.9730 - val_f1_score: 0.0467\n","94/94 [==============================] - 9s 71ms/step - loss: 2.2720 - acc: 0.2150 - auc: 0.7888 - recall: 0.0247 - precision: 0.4327 - hamming_loss: 0.9753 - f1_score: 0.0434\n","***********test accuracy is [2.271965265274048, 0.2150000035762787, 0.7888017892837524, 0.024666666984558105, 0.4327485263347626, 0.9753333330154419, array([0.06666667, 0.        , 0.        , 0.08064517, 0.00985222,\n","       0.09433962, 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.07373272, 0.2413793 , 0.        , 0.08372093],\n","      dtype=float32)] ***************\n","******************* Train time is 500.4122308640001 ***********\n","f1 score is 0.04335577543824911\n"]}],"source":["print(\"*********** Fitting model for 12 batch size and for 1 epochs\")\n","model = compile_model()\n","model.fit(X_train, y_train, batch_size = 12, epochs=1, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"******************* Train time is\", sum(cb.logs), \"***********\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"B_V_swuTQ8jh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649247027728,"user_tz":-330,"elapsed":597547,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}},"outputId":"60a03edc-58fc-4ad5-8cd9-eb33c2909ede"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 24 batch size and for 2 epochs\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","1000/1000 [==============================] - 301s 286ms/step - loss: 1.5881 - acc: 0.4428 - auc_1: 0.9057 - recall_1: 0.2830 - precision_1: 0.6474 - hamming_loss: 0.7170 - f1_score: 0.3732 - val_loss: 3.6155 - val_acc: 0.2700 - val_auc_1: 0.7463 - val_recall_1: 0.1930 - val_precision_1: 0.3578 - val_hamming_loss: 0.8070 - val_f1_score: 0.2186\n","Epoch 2/2\n","1000/1000 [==============================] - 283s 283ms/step - loss: 0.8850 - acc: 0.6791 - auc_1: 0.9701 - recall_1: 0.5865 - precision_1: 0.7891 - hamming_loss: 0.4135 - f1_score: 0.6599 - val_loss: 0.9720 - val_acc: 0.6773 - val_auc_1: 0.9650 - val_recall_1: 0.5983 - val_precision_1: 0.7687 - val_hamming_loss: 0.4017 - val_f1_score: 0.6498\n","94/94 [==============================] - 8s 66ms/step - loss: 1.0104 - acc: 0.6607 - auc_1: 0.9628 - recall_1: 0.5890 - precision_1: 0.7538 - hamming_loss: 0.4110 - f1_score: 0.6381\n","***********test accuracy is [1.0103740692138672, 0.6606666445732117, 0.9628415703773499, 0.5889999866485596, 0.7538396120071411, 0.41100001335144043, array([0.4042553 , 0.60714287, 0.6466166 , 0.7027027 , 0.77157354,\n","       0.8463612 , 0.50167227, 0.60377353, 0.6138614 , 0.7235142 ,\n","       0.379845  , 0.77134985, 0.884058  , 0.32520327, 0.7888889 ],\n","      dtype=float32)] ***************\n","******************* Train time is 1084.627522502 ***********\n","f1 score is 0.6380545715490977\n"]}],"source":["print(\"*********** Fitting model for 24 batch size and for 2 epochs\")\n","model = compile_model()\n","model.fit(X_train, y_train, batch_size = 24, epochs=2, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"******************* Train time is\", sum(cb.logs), \"***********\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"dVMB726UQG3_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"80b7c8ab-cb9e-4640-c9f0-7c38962fac25","executionInfo":{"status":"ok","timestamp":1649247736530,"user_tz":-330,"elapsed":708814,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 36 batch size and for 3 epochs\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","667/667 [==============================] - 236s 328ms/step - loss: 0.6698 - acc: 0.7726 - auc_2: 0.9810 - recall_2: 0.7195 - precision_2: 0.8367 - hamming_loss: 0.2805 - f1_score: 0.7692 - val_loss: 0.8816 - val_acc: 0.7303 - val_auc_2: 0.9708 - val_recall_2: 0.6870 - val_precision_2: 0.7748 - val_hamming_loss: 0.3130 - val_f1_score: 0.7239\n","Epoch 2/3\n","667/667 [==============================] - 221s 331ms/step - loss: 0.3990 - acc: 0.8630 - auc_2: 0.9918 - recall_2: 0.8385 - precision_2: 0.8931 - hamming_loss: 0.1615 - f1_score: 0.8635 - val_loss: 1.7594 - val_acc: 0.6220 - val_auc_2: 0.9287 - val_recall_2: 0.5950 - val_precision_2: 0.6759 - val_hamming_loss: 0.4050 - val_f1_score: 0.6289\n","Epoch 3/3\n","667/667 [==============================] - 217s 325ms/step - loss: 0.2963 - acc: 0.9004 - auc_2: 0.9945 - recall_2: 0.8845 - precision_2: 0.9197 - hamming_loss: 0.1155 - f1_score: 0.9011 - val_loss: 3.9415 - val_acc: 0.3870 - val_auc_2: 0.7706 - val_recall_2: 0.3753 - val_precision_2: 0.4137 - val_hamming_loss: 0.6247 - val_f1_score: 0.3909\n","94/94 [==============================] - 6s 67ms/step - loss: 4.0177 - acc: 0.3840 - auc_2: 0.7653 - recall_2: 0.3703 - precision_2: 0.4077 - hamming_loss: 0.6297 - f1_score: 0.3832\n","***********test accuracy is [4.017659664154053, 0.3840000033378601, 0.7652795314788818, 0.37033334374427795, 0.4077064096927643, 0.6296666860580444, array([0.4090909 , 0.56779665, 0.36567163, 0.36947793, 0.38345864,\n","       0.29835212, 0.41221377, 0.25514406, 0.41575494, 0.2682927 ,\n","       0.2903226 , 0.46879753, 0.4367816 , 0.31199998, 0.49417248],\n","      dtype=float32)] ***************\n","******************* Train time is 1757.8767792060003 ***********\n","f1 score is 0.3831551690896352\n"]}],"source":["print(\"*********** Fitting model for 36 batch size and for 3 epochs\")\n","model = compile_model()\n","model.fit(X_train, y_train, batch_size = 36, epochs=3, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"******************* Train time is\", sum(cb.logs), \"***********\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"AkePK6GNRD3V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649248509603,"user_tz":-330,"elapsed":773101,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}},"outputId":"36941089-e29f-4318-95ab-1914e50ed2a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 48 batch size and for 4 epochs\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/4\n","500/500 [==============================] - 205s 376ms/step - loss: 0.3077 - acc: 0.9070 - auc_3: 0.9938 - recall_3: 0.8875 - precision_3: 0.9298 - hamming_loss: 0.1125 - f1_score: 0.9078 - val_loss: 1.0113 - val_acc: 0.7103 - val_auc_3: 0.9586 - val_recall_3: 0.6783 - val_precision_3: 0.7770 - val_hamming_loss: 0.3217 - val_f1_score: 0.7230\n","Epoch 2/4\n","500/500 [==============================] - 186s 371ms/step - loss: 0.1899 - acc: 0.9439 - auc_3: 0.9961 - recall_3: 0.9357 - precision_3: 0.9520 - hamming_loss: 0.0643 - f1_score: 0.9436 - val_loss: 0.7095 - val_acc: 0.8133 - val_auc_3: 0.9727 - val_recall_3: 0.8037 - val_precision_3: 0.8369 - val_hamming_loss: 0.1963 - val_f1_score: 0.8180\n","Epoch 3/4\n","500/500 [==============================] - 186s 372ms/step - loss: 0.1619 - acc: 0.9528 - auc_3: 0.9967 - recall_3: 0.9477 - precision_3: 0.9585 - hamming_loss: 0.0523 - f1_score: 0.9530 - val_loss: 0.5401 - val_acc: 0.8563 - val_auc_3: 0.9806 - val_recall_3: 0.8470 - val_precision_3: 0.8663 - val_hamming_loss: 0.1530 - val_f1_score: 0.8571\n","Epoch 4/4\n","500/500 [==============================] - 186s 371ms/step - loss: 0.1340 - acc: 0.9589 - auc_3: 0.9976 - recall_3: 0.9542 - precision_3: 0.9642 - hamming_loss: 0.0458 - f1_score: 0.9591 - val_loss: 1.4816 - val_acc: 0.6690 - val_auc_3: 0.9271 - val_recall_3: 0.6447 - val_precision_3: 0.7158 - val_hamming_loss: 0.3553 - val_f1_score: 0.6766\n","94/94 [==============================] - 6s 67ms/step - loss: 1.5368 - acc: 0.6627 - auc_3: 0.9264 - recall_3: 0.6350 - precision_3: 0.7124 - hamming_loss: 0.3650 - f1_score: 0.6686\n","***********test accuracy is [1.5368033647537231, 0.6626666784286499, 0.9263513088226318, 0.6349999904632568, 0.712415874004364, 0.36500000953674316, array([0.668693  , 0.70940167, 0.5559106 , 0.7431694 , 0.77472526,\n","       0.62454873, 0.735955  , 0.58709675, 0.5822102 , 0.64819944,\n","       0.514658  , 0.7726161 , 0.7880597 , 0.65045595, 0.67330676],\n","      dtype=float32)] ***************\n","******************* Train time is 2520.1151498780005 ***********\n","f1 score is 0.6686004360516866\n"]}],"source":["print(\"*********** Fitting model for 48 batch size and for 4 epochs\")\n","model = compile_model()\n","model.fit(X_train, y_train, batch_size = 48, epochs=4, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"******************* Train time is\", sum(cb.logs), \"***********\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"561S_JorTZQP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649249395264,"user_tz":-330,"elapsed":885685,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}},"outputId":"362149dc-be65-49a6-cc51-6d3b9ec270ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 60 batch size and for 5 epochs\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","400/400 [==============================] - 184s 416ms/step - loss: 0.1788 - acc: 0.9498 - auc_4: 0.9968 - recall_4: 0.9367 - precision_4: 0.9637 - hamming_loss: 0.0632 - f1_score: 0.9500 - val_loss: 0.7767 - val_acc: 0.7993 - val_auc_4: 0.9696 - val_recall_4: 0.7810 - val_precision_4: 0.8241 - val_hamming_loss: 0.2190 - val_f1_score: 0.8013\n","Epoch 2/5\n","400/400 [==============================] - 165s 412ms/step - loss: 0.1053 - acc: 0.9721 - auc_4: 0.9980 - recall_4: 0.9697 - precision_4: 0.9753 - hamming_loss: 0.0303 - f1_score: 0.9725 - val_loss: 0.5852 - val_acc: 0.8533 - val_auc_4: 0.9777 - val_recall_4: 0.8460 - val_precision_4: 0.8671 - val_hamming_loss: 0.1540 - val_f1_score: 0.8560\n","Epoch 3/5\n","400/400 [==============================] - 165s 412ms/step - loss: 0.0877 - acc: 0.9753 - auc_4: 0.9985 - recall_4: 0.9733 - precision_4: 0.9774 - hamming_loss: 0.0267 - f1_score: 0.9753 - val_loss: 0.7878 - val_acc: 0.8403 - val_auc_4: 0.9681 - val_recall_4: 0.8330 - val_precision_4: 0.8483 - val_hamming_loss: 0.1670 - val_f1_score: 0.8415\n","Epoch 4/5\n","400/400 [==============================] - 165s 413ms/step - loss: 0.0879 - acc: 0.9785 - auc_4: 0.9983 - recall_4: 0.9764 - precision_4: 0.9806 - hamming_loss: 0.0236 - f1_score: 0.9785 - val_loss: 0.4565 - val_acc: 0.8790 - val_auc_4: 0.9834 - val_recall_4: 0.8707 - val_precision_4: 0.8884 - val_hamming_loss: 0.1293 - val_f1_score: 0.8788\n","Epoch 5/5\n","400/400 [==============================] - 165s 412ms/step - loss: 0.0779 - acc: 0.9798 - auc_4: 0.9985 - recall_4: 0.9784 - precision_4: 0.9815 - hamming_loss: 0.0216 - f1_score: 0.9799 - val_loss: 0.6973 - val_acc: 0.8580 - val_auc_4: 0.9745 - val_recall_4: 0.8540 - val_precision_4: 0.8670 - val_hamming_loss: 0.1460 - val_f1_score: 0.8606\n","94/94 [==============================] - 8s 68ms/step - loss: 0.6786 - acc: 0.8530 - auc_4: 0.9712 - recall_4: 0.8420 - precision_4: 0.8633 - hamming_loss: 0.1580 - f1_score: 0.8529\n","***********test accuracy is [0.6785600185394287, 0.8529999852180481, 0.9711548686027527, 0.8420000076293945, 0.8632946014404297, 0.15800000727176666, array([0.79017854, 0.83425415, 0.8418231 , 0.8733031 , 0.8571429 ,\n","       0.9347259 , 0.79069763, 0.81994456, 0.84705883, 0.8787879 ,\n","       0.8105263 , 0.9164557 , 0.90452266, 0.7710145 , 0.9226803 ],\n","      dtype=float32)] ***************\n","******************* Train time is 3363.146255004 ***********\n","f1 score is 0.8528744061787923\n"]}],"source":["print(\"*********** Fitting model for 60 batch size and for 5 epochs\")\n","model = compile_model()\n","model.fit(X_train, y_train, batch_size = 60, epochs=5, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"******************* Train time is\", sum(cb.logs), \"***********\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"V0qX8aNFTkAf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649250399951,"user_tz":-330,"elapsed":1004706,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}},"outputId":"31ea4d60-8534-405b-f12f-526f847acc23"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 72 batch size and for 6 epochs\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/6\n","334/334 [==============================] - 173s 464ms/step - loss: 0.1254 - acc: 0.9702 - auc_5: 0.9980 - recall_5: 0.9597 - precision_5: 0.9810 - hamming_loss: 0.0402 - f1_score: 0.9702 - val_loss: 1.9625 - val_acc: 0.6437 - val_auc_5: 0.9005 - val_recall_5: 0.6310 - val_precision_5: 0.6734 - val_hamming_loss: 0.3690 - val_f1_score: 0.6517\n","Epoch 2/6\n","334/334 [==============================] - 153s 459ms/step - loss: 0.0665 - acc: 0.9842 - auc_5: 0.9988 - recall_5: 0.9828 - precision_5: 0.9860 - hamming_loss: 0.0172 - f1_score: 0.9844 - val_loss: 0.5200 - val_acc: 0.8813 - val_auc_5: 0.9793 - val_recall_5: 0.8717 - val_precision_5: 0.8916 - val_hamming_loss: 0.1283 - val_f1_score: 0.8814\n","Epoch 3/6\n","334/334 [==============================] - 154s 460ms/step - loss: 0.0592 - acc: 0.9866 - auc_5: 0.9987 - recall_5: 0.9849 - precision_5: 0.9878 - hamming_loss: 0.0151 - f1_score: 0.9864 - val_loss: 0.7986 - val_acc: 0.8500 - val_auc_5: 0.9633 - val_recall_5: 0.8437 - val_precision_5: 0.8635 - val_hamming_loss: 0.1563 - val_f1_score: 0.8538\n","Epoch 4/6\n","334/334 [==============================] - 154s 460ms/step - loss: 0.0549 - acc: 0.9858 - auc_5: 0.9988 - recall_5: 0.9847 - precision_5: 0.9871 - hamming_loss: 0.0153 - f1_score: 0.9859 - val_loss: 0.9231 - val_acc: 0.7723 - val_auc_5: 0.9606 - val_recall_5: 0.7533 - val_precision_5: 0.8132 - val_hamming_loss: 0.2467 - val_f1_score: 0.7812\n","Epoch 5/6\n","334/334 [==============================] - 153s 458ms/step - loss: 0.0592 - acc: 0.9868 - auc_5: 0.9986 - recall_5: 0.9858 - precision_5: 0.9876 - hamming_loss: 0.0143 - f1_score: 0.9867 - val_loss: 0.9590 - val_acc: 0.8177 - val_auc_5: 0.9596 - val_recall_5: 0.8117 - val_precision_5: 0.8265 - val_hamming_loss: 0.1883 - val_f1_score: 0.8178\n","Epoch 6/6\n","334/334 [==============================] - 153s 458ms/step - loss: 0.0563 - acc: 0.9857 - auc_5: 0.9987 - recall_5: 0.9847 - precision_5: 0.9870 - hamming_loss: 0.0153 - f1_score: 0.9858 - val_loss: 1.3518 - val_acc: 0.7737 - val_auc_5: 0.9429 - val_recall_5: 0.7650 - val_precision_5: 0.7860 - val_hamming_loss: 0.2350 - val_f1_score: 0.7750\n","94/94 [==============================] - 6s 67ms/step - loss: 1.4022 - acc: 0.7630 - auc_5: 0.9399 - recall_5: 0.7520 - precision_5: 0.7790 - hamming_loss: 0.2480 - f1_score: 0.7642\n","***********test accuracy is [1.4021908044815063, 0.7630000114440918, 0.9398919939994812, 0.7519999742507935, 0.7790055274963379, 0.24799999594688416, array([0.8144045 , 0.79139787, 0.6875    , 0.8222811 , 0.8       ,\n","       0.70289856, 0.7732697 , 0.68085104, 0.6941431 , 0.8019802 ,\n","       0.6433121 , 0.86734694, 0.88220555, 0.74233127, 0.7597254 ],\n","      dtype=float32)] ***************\n","******************* Train time is 4303.073661699002 ***********\n","f1 score is 0.7642431577046712\n"]}],"source":["print(\"*********** Fitting model for 72 batch size and for 6 epochs\")\n","model = compile_model()\n","model.fit(X_train, y_train, batch_size = 72, epochs=6, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"******************* Train time is\", sum(cb.logs), \"***********\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Uh0I822_Tpdn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649251468223,"user_tz":-330,"elapsed":1068291,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}},"outputId":"cdd0e7ec-7b27-450c-87a4-9d204ae08d9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 84 batch size and for 7 epochs\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/7\n","286/286 [==============================] - 163s 508ms/step - loss: 0.1235 - acc: 0.9744 - auc_6: 0.9975 - recall_6: 0.9645 - precision_6: 0.9834 - hamming_loss: 0.0355 - f1_score: 0.9739 - val_loss: 1.0814 - val_acc: 0.7957 - val_auc_6: 0.9477 - val_recall_6: 0.7890 - val_precision_6: 0.8070 - val_hamming_loss: 0.2110 - val_f1_score: 0.7990\n","Epoch 2/7\n","286/286 [==============================] - 143s 502ms/step - loss: 0.0472 - acc: 0.9887 - auc_6: 0.9987 - recall_6: 0.9876 - precision_6: 0.9901 - hamming_loss: 0.0124 - f1_score: 0.9888 - val_loss: 0.4762 - val_acc: 0.9103 - val_auc_6: 0.9807 - val_recall_6: 0.9080 - val_precision_6: 0.9184 - val_hamming_loss: 0.0920 - val_f1_score: 0.9130\n","Epoch 3/7\n","286/286 [==============================] - 143s 502ms/step - loss: 0.0658 - acc: 0.9894 - auc_6: 0.9989 - recall_6: 0.9885 - precision_6: 0.9902 - hamming_loss: 0.0115 - f1_score: 0.9894 - val_loss: 0.6028 - val_acc: 0.8420 - val_auc_6: 0.9794 - val_recall_6: 0.8280 - val_precision_6: 0.8694 - val_hamming_loss: 0.1720 - val_f1_score: 0.8475\n","Epoch 4/7\n","286/286 [==============================] - 144s 502ms/step - loss: 0.0449 - acc: 0.9898 - auc_6: 0.9990 - recall_6: 0.9893 - precision_6: 0.9907 - hamming_loss: 0.0107 - f1_score: 0.9900 - val_loss: 0.8997 - val_acc: 0.8293 - val_auc_6: 0.9616 - val_recall_6: 0.8220 - val_precision_6: 0.8515 - val_hamming_loss: 0.1780 - val_f1_score: 0.8355\n","Epoch 5/7\n","286/286 [==============================] - 143s 501ms/step - loss: 0.0375 - acc: 0.9908 - auc_6: 0.9990 - recall_6: 0.9900 - precision_6: 0.9916 - hamming_loss: 0.0100 - f1_score: 0.9908 - val_loss: 3.4848 - val_acc: 0.6340 - val_auc_6: 0.8681 - val_recall_6: 0.6257 - val_precision_6: 0.6506 - val_hamming_loss: 0.3743 - val_f1_score: 0.6386\n","Epoch 6/7\n","286/286 [==============================] - 144s 502ms/step - loss: 0.0457 - acc: 0.9909 - auc_6: 0.9991 - recall_6: 0.9902 - precision_6: 0.9914 - hamming_loss: 0.0098 - f1_score: 0.9908 - val_loss: 0.6344 - val_acc: 0.8747 - val_auc_6: 0.9731 - val_recall_6: 0.8723 - val_precision_6: 0.8817 - val_hamming_loss: 0.1277 - val_f1_score: 0.8772\n","Epoch 7/7\n","286/286 [==============================] - 144s 502ms/step - loss: 0.0362 - acc: 0.9921 - auc_6: 0.9991 - recall_6: 0.9914 - precision_6: 0.9927 - hamming_loss: 0.0086 - f1_score: 0.9920 - val_loss: 0.6928 - val_acc: 0.8510 - val_auc_6: 0.9708 - val_recall_6: 0.8453 - val_precision_6: 0.8694 - val_hamming_loss: 0.1547 - val_f1_score: 0.8580\n","94/94 [==============================] - 6s 67ms/step - loss: 0.6952 - acc: 0.8557 - auc_6: 0.9717 - recall_6: 0.8483 - precision_6: 0.8695 - hamming_loss: 0.1517 - f1_score: 0.8593\n","***********test accuracy is [0.6951754689216614, 0.8556666374206543, 0.9717326164245605, 0.8483333587646484, 0.869490921497345, 0.15166667103767395, array([0.86352354, 0.86233765, 0.8190955 , 0.79999995, 0.89247316,\n","       0.9414758 , 0.87027025, 0.7888889 , 0.8716706 , 0.9023747 ,\n","       0.8000001 , 0.8946015 , 0.8872549 , 0.79444444, 0.9017632 ],\n","      dtype=float32)] ***************\n","******************* Train time is 5327.043100336003 ***********\n","f1 score is 0.8593449433644612\n"]}],"source":["print(\"*********** Fitting model for 84 batch size and for 7 epochs\")\n","model = compile_model()\n","model.fit(X_train, y_train, batch_size = 84, epochs=7, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"******************* Train time is\", sum(cb.logs), \"***********\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"5aJD5LugTwtS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649252656509,"user_tz":-330,"elapsed":1188299,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}},"outputId":"54f443d2-7bcc-4589-9be8-ca337c32a160"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 96 batch size and for 8 epochs\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/8\n","250/250 [==============================] - 158s 561ms/step - loss: 0.0889 - acc: 0.9822 - auc_7: 0.9989 - recall_7: 0.9719 - precision_7: 0.9913 - hamming_loss: 0.0281 - f1_score: 0.9815 - val_loss: 0.5866 - val_acc: 0.8867 - val_auc_7: 0.9748 - val_recall_7: 0.8813 - val_precision_7: 0.8938 - val_hamming_loss: 0.1187 - val_f1_score: 0.8874\n","Epoch 2/8\n","250/250 [==============================] - 138s 554ms/step - loss: 0.0371 - acc: 0.9927 - auc_7: 0.9991 - recall_7: 0.9921 - precision_7: 0.9932 - hamming_loss: 0.0079 - f1_score: 0.9927 - val_loss: 0.9372 - val_acc: 0.8573 - val_auc_7: 0.9639 - val_recall_7: 0.8527 - val_precision_7: 0.8692 - val_hamming_loss: 0.1473 - val_f1_score: 0.8613\n","Epoch 3/8\n","250/250 [==============================] - 138s 553ms/step - loss: 0.0312 - acc: 0.9926 - auc_7: 0.9992 - recall_7: 0.9921 - precision_7: 0.9932 - hamming_loss: 0.0079 - f1_score: 0.9926 - val_loss: 1.1345 - val_acc: 0.7980 - val_auc_7: 0.9476 - val_recall_7: 0.7910 - val_precision_7: 0.8141 - val_hamming_loss: 0.2090 - val_f1_score: 0.8013\n","Epoch 4/8\n","250/250 [==============================] - 138s 554ms/step - loss: 0.0320 - acc: 0.9933 - auc_7: 0.9991 - recall_7: 0.9927 - precision_7: 0.9936 - hamming_loss: 0.0073 - f1_score: 0.9931 - val_loss: 0.9376 - val_acc: 0.8413 - val_auc_7: 0.9567 - val_recall_7: 0.8373 - val_precision_7: 0.8481 - val_hamming_loss: 0.1627 - val_f1_score: 0.8441\n","Epoch 5/8\n","250/250 [==============================] - 139s 555ms/step - loss: 0.0494 - acc: 0.9935 - auc_7: 0.9990 - recall_7: 0.9933 - precision_7: 0.9939 - hamming_loss: 0.0067 - f1_score: 0.9936 - val_loss: 1.1420 - val_acc: 0.8247 - val_auc_7: 0.9586 - val_recall_7: 0.8167 - val_precision_7: 0.8393 - val_hamming_loss: 0.1833 - val_f1_score: 0.8282\n","Epoch 6/8\n","250/250 [==============================] - 138s 554ms/step - loss: 0.0424 - acc: 0.9934 - auc_7: 0.9992 - recall_7: 0.9929 - precision_7: 0.9937 - hamming_loss: 0.0071 - f1_score: 0.9933 - val_loss: 0.6302 - val_acc: 0.8773 - val_auc_7: 0.9754 - val_recall_7: 0.8710 - val_precision_7: 0.8876 - val_hamming_loss: 0.1290 - val_f1_score: 0.8792\n","Epoch 7/8\n","250/250 [==============================] - 139s 554ms/step - loss: 0.0245 - acc: 0.9942 - auc_7: 0.9993 - recall_7: 0.9936 - precision_7: 0.9947 - hamming_loss: 0.0064 - f1_score: 0.9941 - val_loss: 0.7102 - val_acc: 0.9023 - val_auc_7: 0.9693 - val_recall_7: 0.9013 - val_precision_7: 0.9065 - val_hamming_loss: 0.0987 - val_f1_score: 0.9043\n","Epoch 8/8\n","250/250 [==============================] - 138s 553ms/step - loss: 0.0358 - acc: 0.9935 - auc_7: 0.9991 - recall_7: 0.9930 - precision_7: 0.9939 - hamming_loss: 0.0070 - f1_score: 0.9934 - val_loss: 0.6734 - val_acc: 0.8520 - val_auc_7: 0.9729 - val_recall_7: 0.8380 - val_precision_7: 0.8738 - val_hamming_loss: 0.1620 - val_f1_score: 0.8554\n","94/94 [==============================] - 6s 66ms/step - loss: 0.6648 - acc: 0.8533 - auc_7: 0.9743 - recall_7: 0.8420 - precision_7: 0.8728 - hamming_loss: 0.1580 - f1_score: 0.8567\n","***********test accuracy is [0.6648156046867371, 0.8533333539962769, 0.9743264317512512, 0.8420000076293945, 0.8728403449058533, 0.15800000727176666, array([0.8508288 , 0.859155  , 0.7799443 , 0.8173077 , 0.8624339 ,\n","       0.9275362 , 0.8585131 , 0.8179419 , 0.85238093, 0.8729282 ,\n","       0.8146341 , 0.87362635, 0.9381443 , 0.8071066 , 0.91851854],\n","      dtype=float32)] ***************\n","******************* Train time is 6454.468905022001 ***********\n","f1 score is 0.8567333340644836\n"]}],"source":["print(\"*********** Fitting model for 96 batch size and for 8 epochs\")\n","model = compile_model()\n","model.fit(X_train, y_train, batch_size = 96, epochs=8, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"******************* Train time is\", sum(cb.logs), \"***********\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"-Qx-cWd7T3Pp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649253868015,"user_tz":-330,"elapsed":1211524,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}},"outputId":"c86b13ca-cb57-4cdf-fe30-a26420deda8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 108 batch size and for 9 epochs\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/9\n","223/223 [==============================] - 151s 597ms/step - loss: 0.0723 - acc: 0.9845 - auc_8: 0.9991 - recall_8: 0.9754 - precision_8: 0.9925 - hamming_loss: 0.0246 - f1_score: 0.9839 - val_loss: 0.6480 - val_acc: 0.8860 - val_auc_8: 0.9717 - val_recall_8: 0.8830 - val_precision_8: 0.8931 - val_hamming_loss: 0.1170 - val_f1_score: 0.8886\n","Epoch 2/9\n","223/223 [==============================] - 131s 589ms/step - loss: 0.0234 - acc: 0.9947 - auc_8: 0.9994 - recall_8: 0.9944 - precision_8: 0.9950 - hamming_loss: 0.0056 - f1_score: 0.9947 - val_loss: 8.2270 - val_acc: 0.4800 - val_auc_8: 0.7749 - val_recall_8: 0.4683 - val_precision_8: 0.5007 - val_hamming_loss: 0.5317 - val_f1_score: 0.4911\n","Epoch 3/9\n","223/223 [==============================] - 132s 594ms/step - loss: 0.0244 - acc: 0.9944 - auc_8: 0.9993 - recall_8: 0.9941 - precision_8: 0.9948 - hamming_loss: 0.0059 - f1_score: 0.9945 - val_loss: 2.7284 - val_acc: 0.7157 - val_auc_8: 0.8958 - val_recall_8: 0.7107 - val_precision_8: 0.7249 - val_hamming_loss: 0.2893 - val_f1_score: 0.7145\n","Epoch 4/9\n","223/223 [==============================] - 131s 587ms/step - loss: 0.0240 - acc: 0.9940 - auc_8: 0.9994 - recall_8: 0.9934 - precision_8: 0.9947 - hamming_loss: 0.0066 - f1_score: 0.9940 - val_loss: 1.0593 - val_acc: 0.8750 - val_auc_8: 0.9585 - val_recall_8: 0.8717 - val_precision_8: 0.8793 - val_hamming_loss: 0.1283 - val_f1_score: 0.8764\n","Epoch 5/9\n","223/223 [==============================] - 131s 588ms/step - loss: 0.0237 - acc: 0.9950 - auc_8: 0.9994 - recall_8: 0.9945 - precision_8: 0.9955 - hamming_loss: 0.0055 - f1_score: 0.9950 - val_loss: 0.7768 - val_acc: 0.8537 - val_auc_8: 0.9677 - val_recall_8: 0.8457 - val_precision_8: 0.8638 - val_hamming_loss: 0.1543 - val_f1_score: 0.8540\n","Epoch 6/9\n","223/223 [==============================] - 131s 587ms/step - loss: 0.0671 - acc: 0.9945 - auc_8: 0.9991 - recall_8: 0.9942 - precision_8: 0.9948 - hamming_loss: 0.0058 - f1_score: 0.9945 - val_loss: 0.9889 - val_acc: 0.7790 - val_auc_8: 0.9555 - val_recall_8: 0.7580 - val_precision_8: 0.8110 - val_hamming_loss: 0.2420 - val_f1_score: 0.7844\n","Epoch 7/9\n","223/223 [==============================] - 131s 588ms/step - loss: 0.0434 - acc: 0.9951 - auc_8: 0.9992 - recall_8: 0.9949 - precision_8: 0.9954 - hamming_loss: 0.0051 - f1_score: 0.9951 - val_loss: 1.0996 - val_acc: 0.8720 - val_auc_8: 0.9602 - val_recall_8: 0.8710 - val_precision_8: 0.8768 - val_hamming_loss: 0.1290 - val_f1_score: 0.8740\n","Epoch 8/9\n","223/223 [==============================] - 131s 588ms/step - loss: 0.0220 - acc: 0.9952 - auc_8: 0.9993 - recall_8: 0.9948 - precision_8: 0.9954 - hamming_loss: 0.0052 - f1_score: 0.9951 - val_loss: 3.4034 - val_acc: 0.5527 - val_auc_8: 0.8329 - val_recall_8: 0.5380 - val_precision_8: 0.5783 - val_hamming_loss: 0.4620 - val_f1_score: 0.5497\n","Epoch 9/9\n","223/223 [==============================] - 131s 587ms/step - loss: 0.0281 - acc: 0.9950 - auc_8: 0.9995 - recall_8: 0.9942 - precision_8: 0.9953 - hamming_loss: 0.0058 - f1_score: 0.9948 - val_loss: 8.9228 - val_acc: 0.4517 - val_auc_8: 0.7416 - val_recall_8: 0.4503 - val_precision_8: 0.4573 - val_hamming_loss: 0.5497 - val_f1_score: 0.4727\n","94/94 [==============================] - 6s 66ms/step - loss: 8.6441 - acc: 0.4663 - auc_8: 0.7475 - recall_8: 0.4627 - precision_8: 0.4715 - hamming_loss: 0.5373 - f1_score: 0.4863\n","***********test accuracy is [8.64410400390625, 0.4663333296775818, 0.7474796175956726, 0.46266666054725647, 0.47146740555763245, 0.5373333096504211, array([0.40800002, 0.72727275, 0.3809524 , 0.6089552 , 0.61077845,\n","       0.32233742, 0.5810056 , 0.2672414 , 0.44124705, 0.29661018,\n","       0.4876325 , 0.38434985, 0.6688103 , 0.59078586, 0.5182482 ],\n","      dtype=float32)] ***************\n","******************* Train time is 7654.863783961001 ***********\n","f1 score is 0.48628181020418804\n"]}],"source":["print(\"*********** Fitting model for 108 batch size and for 9 epochs\")\n","model = compile_model()\n","model.fit(X_train, y_train, batch_size = 108, epochs=9, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"******************* Train time is\", sum(cb.logs), \"***********\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"ZjnVPXyDT8Pb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649255233625,"user_tz":-330,"elapsed":1365932,"user":{"displayName":"MASK TALKS","userId":"16201492162619521718"}},"outputId":"a6a4f52a-1674-47af-af9d-a3fc05b4e8ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 120 batch size and for 10 epochs\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 148s 652ms/step - loss: 0.0862 - acc: 0.9838 - auc_9: 0.9990 - recall_9: 0.9720 - precision_9: 0.9926 - hamming_loss: 0.0280 - f1_score: 0.9822 - val_loss: 1.8571 - val_acc: 0.6713 - val_auc_9: 0.9069 - val_recall_9: 0.6547 - val_precision_9: 0.6997 - val_hamming_loss: 0.3453 - val_f1_score: 0.6895\n","Epoch 2/10\n","200/200 [==============================] - 128s 642ms/step - loss: 0.0197 - acc: 0.9957 - auc_9: 0.9994 - recall_9: 0.9954 - precision_9: 0.9961 - hamming_loss: 0.0046 - f1_score: 0.9957 - val_loss: 0.8526 - val_acc: 0.8610 - val_auc_9: 0.9668 - val_recall_9: 0.8533 - val_precision_9: 0.8749 - val_hamming_loss: 0.1467 - val_f1_score: 0.8626\n","Epoch 3/10\n","200/200 [==============================] - 128s 642ms/step - loss: 0.0316 - acc: 0.9954 - auc_9: 0.9994 - recall_9: 0.9948 - precision_9: 0.9956 - hamming_loss: 0.0052 - f1_score: 0.9952 - val_loss: 1.3233 - val_acc: 0.8373 - val_auc_9: 0.9446 - val_recall_9: 0.8360 - val_precision_9: 0.8456 - val_hamming_loss: 0.1640 - val_f1_score: 0.8411\n","Epoch 4/10\n","200/200 [==============================] - 128s 642ms/step - loss: 0.0189 - acc: 0.9956 - auc_9: 0.9996 - recall_9: 0.9952 - precision_9: 0.9960 - hamming_loss: 0.0048 - f1_score: 0.9956 - val_loss: 0.5149 - val_acc: 0.9147 - val_auc_9: 0.9773 - val_recall_9: 0.9110 - val_precision_9: 0.9205 - val_hamming_loss: 0.0890 - val_f1_score: 0.9152\n","Epoch 5/10\n","200/200 [==============================] - 129s 643ms/step - loss: 0.0294 - acc: 0.9958 - auc_9: 0.9995 - recall_9: 0.9958 - precision_9: 0.9962 - hamming_loss: 0.0042 - f1_score: 0.9960 - val_loss: 1.0396 - val_acc: 0.8790 - val_auc_9: 0.9630 - val_recall_9: 0.8770 - val_precision_9: 0.8844 - val_hamming_loss: 0.1230 - val_f1_score: 0.8806\n","Epoch 6/10\n","200/200 [==============================] - 128s 643ms/step - loss: 0.0206 - acc: 0.9956 - auc_9: 0.9996 - recall_9: 0.9953 - precision_9: 0.9959 - hamming_loss: 0.0047 - f1_score: 0.9956 - val_loss: 4.9118 - val_acc: 0.5467 - val_auc_9: 0.8066 - val_recall_9: 0.5413 - val_precision_9: 0.5585 - val_hamming_loss: 0.4587 - val_f1_score: 0.5620\n","Epoch 7/10\n","200/200 [==============================] - 128s 642ms/step - loss: 0.0219 - acc: 0.9963 - auc_9: 0.9994 - recall_9: 0.9959 - precision_9: 0.9965 - hamming_loss: 0.0041 - f1_score: 0.9962 - val_loss: 0.5645 - val_acc: 0.9170 - val_auc_9: 0.9751 - val_recall_9: 0.9167 - val_precision_9: 0.9191 - val_hamming_loss: 0.0833 - val_f1_score: 0.9181\n","Epoch 8/10\n","200/200 [==============================] - 128s 642ms/step - loss: 0.0195 - acc: 0.9952 - auc_9: 0.9995 - recall_9: 0.9948 - precision_9: 0.9958 - hamming_loss: 0.0052 - f1_score: 0.9953 - val_loss: 0.8859 - val_acc: 0.8507 - val_auc_9: 0.9633 - val_recall_9: 0.8447 - val_precision_9: 0.8657 - val_hamming_loss: 0.1553 - val_f1_score: 0.8561\n","Epoch 9/10\n","200/200 [==============================] - 128s 642ms/step - loss: 0.0242 - acc: 0.9959 - auc_9: 0.9994 - recall_9: 0.9955 - precision_9: 0.9961 - hamming_loss: 0.0045 - f1_score: 0.9958 - val_loss: 1.0898 - val_acc: 0.8097 - val_auc_9: 0.9511 - val_recall_9: 0.7997 - val_precision_9: 0.8219 - val_hamming_loss: 0.2003 - val_f1_score: 0.8093\n","Epoch 10/10\n","200/200 [==============================] - 128s 642ms/step - loss: 0.0260 - acc: 0.9967 - auc_9: 0.9994 - recall_9: 0.9963 - precision_9: 0.9969 - hamming_loss: 0.0037 - f1_score: 0.9966 - val_loss: 0.7247 - val_acc: 0.8930 - val_auc_9: 0.9700 - val_recall_9: 0.8903 - val_precision_9: 0.8984 - val_hamming_loss: 0.1097 - val_f1_score: 0.8942\n","94/94 [==============================] - 8s 67ms/step - loss: 0.6717 - acc: 0.8940 - auc_9: 0.9720 - recall_9: 0.8923 - precision_9: 0.8995 - hamming_loss: 0.1077 - f1_score: 0.8962\n","***********test accuracy is [0.6716787815093994, 0.8939999938011169, 0.9720393419265747, 0.8923333287239075, 0.8995295763015747, 0.10766666382551193, array([0.8743169 , 0.8779221 , 0.87677723, 0.84412473, 0.8817204 ,\n","       0.9722922 , 0.8811189 , 0.9017632 , 0.91183877, 0.9363868 ,\n","       0.86699504, 0.9349398 , 0.9316456 , 0.849642  , 0.9016393 ],\n","      dtype=float32)] ***************\n","******************* Train time is 8959.172264169 ***********\n","f1 score is 0.8962081948916117\n"]}],"source":["print(\"*********** Fitting model for 120 batch size and for 10 epochs\")\n","model = compile_model()\n","model.fit(X_train, y_train, batch_size = 120, epochs=10, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"******************* Train time is\", sum(cb.logs), \"***********\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]}]}