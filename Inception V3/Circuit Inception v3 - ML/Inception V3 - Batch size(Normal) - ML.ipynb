{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Inception V3 - Batch size(Normal) - ML.ipynb","provenance":[],"authorship_tag":"ABX9TyP8vkJSKHTGrXi6pIjhOhGw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MfZr5GpLfV8M"},"source":["### Mounting drive on Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20378,"status":"ok","timestamp":1643653788754,"user":{"displayName":"Minor Project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14441173230682961799"},"user_tz":-330},"id":"efjsRr4LAtas","outputId":"16e02158-8c7e-49d2-e08a-c1d4d67c3727"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount = True)"]},{"cell_type":"markdown","metadata":{"id":"yYQAlX3dFz2E"},"source":["###Libraries"]},{"cell_type":"code","source":["!pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XR_v6BD4p4nV","executionInfo":{"status":"ok","timestamp":1643653849287,"user_tz":-330,"elapsed":3535,"user":{"displayName":"Minor Project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14441173230682961799"}},"outputId":"45c9a5ee-e91f-4c88-d552-419cdc5ac84b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.15.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tBQUozfKF1sR"},"outputs":[],"source":["import os\n","import cv2\n","import os\n","import h5py\n","import numpy as np\n","import pickle\n","from tqdm import tqdm\n","from PIL import Image\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","os.chdir('/gdrive/My Drive/')\n","from numpy import savez_compressed\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageEnhance\n","import tensorflow_datasets as tfds\n","from tensorflow_addons.metrics import HammingLoss\n","from tensorflow_addons.metrics import F1Score\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.applications.inception_v3 import preprocess_input\n","from tensorflow.keras import layers, models\n","import tensorflow.keras as keras\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from keras.models import Sequential, load_model\n","from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model"]},{"cell_type":"markdown","metadata":{"id":"u9ifuITblgM6"},"source":["## Effect of changing Batch size"]},{"cell_type":"markdown","metadata":{"id":"5N71D74q9Lzs"},"source":["### For ImageNet as a source"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xF9ByEKST5M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643653859808,"user_tz":-330,"elapsed":5413,"user":{"displayName":"Minor Project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14441173230682961799"}},"outputId":"863ba788-aeb3-4ee2-82ad-c2afb8fd1d89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87916544/87910968 [==============================] - 0s 0us/step\n","87924736/87910968 [==============================] - 0s 0us/step\n"]}],"source":["from tensorflow.keras.applications.inception_v3 import InceptionV3\n","\n","from timeit import default_timer as timer\n","\n","class TimingCallback(keras.callbacks.Callback):\n","    def __init__(self, logs={}):\n","        self.logs=[]\n","    def on_epoch_begin(self, epoch, logs={}):\n","        self.starttime = timer()\n","    def on_epoch_end(self, epoch, logs={}):\n","        self.logs.append(timer()-self.starttime)\n","\n","cb = TimingCallback()\n","\n","pre_trained_model = InceptionV3(input_shape = (96, 96, 3), \n","                                include_top = False, \n","                                weights = 'None')\n","#for layer in pre_trained_model.layers:\n","#  layer.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Chb96JOmSeH_"},"outputs":[],"source":["def compile_model():\n","  from tensorflow.keras.optimizers import RMSprop\n","\n","  # Flatten the output layer to 1 dimension\n","  x = layers.Flatten()(pre_trained_model.output)\n","\n","  # Add a fully connected layer with \"num_neurons\" hidden units and ReLU activation\n","  x = layers.Dense(2000, activation='relu')(x)\n","\n","  x = layers.Dense(1000, activation='relu')(x)\n","\n","  x = layers.Dense(500, activation='relu')(x)                  \n","  \n","  # Add a final sigmoid layer for classification\n","  x = layers.Dense  (15, activation='softmax')(x)           \n","\n","  model = Model( pre_trained_model.input, x) \n","\n","  model.compile(optimizer = RMSprop(lr=0.0001), \n","              loss = 'categorical_crossentropy', \n","              metrics = ['acc', tf.keras.metrics.AUC(), tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), HammingLoss(threshold=0.5, mode='multiclass'), F1Score(num_classes= 15, threshold=0.5)])\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVJdiajZSizq"},"outputs":[],"source":["data = np.load('Xtrain.npy', allow_pickle=True)\n","labels = np.load('ytrain.npy', allow_pickle=True)\n","\n","X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size = 0.2, random_state = 42, stratify = labels)\n","X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42, stratify = y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a80vwffRSlxP"},"outputs":[],"source":["y_train = to_categorical(y_train, 15)\n","y_val = to_categorical(y_val, 15)\n","y_test = to_categorical(y_test, 15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8uVpDFHrSwnH","outputId":"40d7c35d-3038-42ea-ae0d-7f502a3c99d6","executionInfo":{"status":"ok","timestamp":1643655969231,"user_tz":-330,"elapsed":2101666,"user":{"displayName":"Minor Project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14441173230682961799"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for Batch size of 12 ***************\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","2000/2000 [==============================] - 67s 23ms/step - loss: 4.4563 - acc: 0.1560 - auc: 0.6260 - recall: 0.0547 - precision: 0.1930 - hamming_loss: 0.9453 - val_loss: 2.5564 - val_acc: 0.2097 - val_auc: 0.7029 - val_recall: 0.0517 - val_precision: 0.4144 - val_hamming_loss: 0.9483\n","Epoch 2/10\n","2000/2000 [==============================] - 48s 24ms/step - loss: 2.3941 - acc: 0.2390 - auc: 0.7450 - recall: 0.0767 - precision: 0.4934 - hamming_loss: 0.9233 - val_loss: 2.2713 - val_acc: 0.2800 - val_auc: 0.7719 - val_recall: 0.0920 - val_precision: 0.5987 - val_hamming_loss: 0.9080\n","Epoch 3/10\n","2000/2000 [==============================] - 46s 23ms/step - loss: 2.2091 - acc: 0.2945 - auc: 0.7905 - recall: 0.1163 - precision: 0.5694 - hamming_loss: 0.8838 - val_loss: 2.1050 - val_acc: 0.3177 - val_auc: 0.8134 - val_recall: 0.1120 - val_precision: 0.6388 - val_hamming_loss: 0.8880\n","Epoch 4/10\n","2000/2000 [==============================] - 45s 23ms/step - loss: 2.0901 - acc: 0.3269 - auc: 0.8169 - recall: 0.1499 - precision: 0.6113 - hamming_loss: 0.8501 - val_loss: 2.0302 - val_acc: 0.3493 - val_auc: 0.8263 - val_recall: 0.1507 - val_precision: 0.6357 - val_hamming_loss: 0.8493\n","Epoch 5/10\n","2000/2000 [==============================] - 46s 23ms/step - loss: 2.0040 - acc: 0.3559 - auc: 0.8345 - recall: 0.1813 - precision: 0.6386 - hamming_loss: 0.8187 - val_loss: 2.0055 - val_acc: 0.3287 - val_auc: 0.8330 - val_recall: 0.1403 - val_precision: 0.6725 - val_hamming_loss: 0.8597\n","Epoch 6/10\n","2000/2000 [==============================] - 46s 23ms/step - loss: 1.9406 - acc: 0.3770 - auc: 0.8468 - recall: 0.2035 - precision: 0.6502 - hamming_loss: 0.7965 - val_loss: 1.8951 - val_acc: 0.3967 - val_auc: 0.8587 - val_recall: 0.2150 - val_precision: 0.6515 - val_hamming_loss: 0.7850\n","Epoch 7/10\n","2000/2000 [==============================] - 47s 23ms/step - loss: 1.8795 - acc: 0.3930 - auc: 0.8582 - recall: 0.2272 - precision: 0.6627 - hamming_loss: 0.7728 - val_loss: 2.0126 - val_acc: 0.3447 - val_auc: 0.8372 - val_recall: 0.2013 - val_precision: 0.5939 - val_hamming_loss: 0.7987\n","Epoch 8/10\n","2000/2000 [==============================] - 46s 23ms/step - loss: 1.8436 - acc: 0.4080 - auc: 0.8649 - recall: 0.2463 - precision: 0.6750 - hamming_loss: 0.7538 - val_loss: 1.9372 - val_acc: 0.3843 - val_auc: 0.8564 - val_recall: 0.2390 - val_precision: 0.6306 - val_hamming_loss: 0.7610\n","Epoch 9/10\n","2000/2000 [==============================] - 47s 23ms/step - loss: 1.8104 - acc: 0.4188 - auc: 0.8706 - recall: 0.2590 - precision: 0.6780 - hamming_loss: 0.7410 - val_loss: 1.8317 - val_acc: 0.3993 - val_auc: 0.8684 - val_recall: 0.2170 - val_precision: 0.6739 - val_hamming_loss: 0.7830\n","Epoch 10/10\n","2000/2000 [==============================] - 46s 23ms/step - loss: 1.7760 - acc: 0.4297 - auc: 0.8764 - recall: 0.2719 - precision: 0.6849 - hamming_loss: 0.7281 - val_loss: 1.9927 - val_acc: 0.4053 - val_auc: 0.8515 - val_recall: 0.2593 - val_precision: 0.6516 - val_hamming_loss: 0.7407\n","94/94 [==============================] - 5s 32ms/step - loss: 2.0471 - acc: 0.4180 - auc: 0.8451 - recall: 0.2710 - precision: 0.6342 - hamming_loss: 0.7290\n","***********test accuracy is [2.047128677368164, 0.4180000126361847, 0.8451372385025024, 0.2709999978542328, 0.634165346622467, 0.7289999723434448] ***************\n","***********train time is 484.3728761809999 ***************\n","*********** Fitting model for Batch size of 24 ***************\n","Epoch 1/10\n","1000/1000 [==============================] - 33s 28ms/step - loss: 5.2417 - acc: 0.1487 - auc_1: 0.6112 - recall_1: 0.0593 - precision_1: 0.1816 - hamming_loss: 0.9407 - val_loss: 2.3932 - val_acc: 0.2453 - val_auc_1: 0.7280 - val_recall_1: 0.0560 - val_precision_1: 0.5874 - val_hamming_loss: 0.9440\n","Epoch 2/10\n","1000/1000 [==============================] - 26s 26ms/step - loss: 2.3973 - acc: 0.2474 - auc_1: 0.7436 - recall_1: 0.0800 - precision_1: 0.4983 - hamming_loss: 0.9200 - val_loss: 2.2245 - val_acc: 0.2763 - val_auc_1: 0.7861 - val_recall_1: 0.0833 - val_precision_1: 0.5656 - val_hamming_loss: 0.9167\n","Epoch 3/10\n","1000/1000 [==============================] - 26s 26ms/step - loss: 2.1833 - acc: 0.3058 - auc_1: 0.7959 - recall_1: 0.1262 - precision_1: 0.5814 - hamming_loss: 0.8738 - val_loss: 2.3887 - val_acc: 0.2677 - val_auc_1: 0.7765 - val_recall_1: 0.1390 - val_precision_1: 0.4212 - val_hamming_loss: 0.8610\n","Epoch 4/10\n","1000/1000 [==============================] - 25s 25ms/step - loss: 2.0297 - acc: 0.3527 - auc_1: 0.8272 - recall_1: 0.1679 - precision_1: 0.6234 - hamming_loss: 0.8321 - val_loss: 2.0096 - val_acc: 0.3413 - val_auc_1: 0.8315 - val_recall_1: 0.1513 - val_precision_1: 0.6288 - val_hamming_loss: 0.8487\n","Epoch 5/10\n","1000/1000 [==============================] - 25s 25ms/step - loss: 1.9185 - acc: 0.3812 - auc_1: 0.8492 - recall_1: 0.2026 - precision_1: 0.6472 - hamming_loss: 0.7974 - val_loss: 1.9196 - val_acc: 0.3780 - val_auc_1: 0.8482 - val_recall_1: 0.1943 - val_precision_1: 0.6633 - val_hamming_loss: 0.8057\n","Epoch 6/10\n","1000/1000 [==============================] - 25s 25ms/step - loss: 1.8342 - acc: 0.4127 - auc_1: 0.8637 - recall_1: 0.2396 - precision_1: 0.6738 - hamming_loss: 0.7604 - val_loss: 2.2362 - val_acc: 0.3420 - val_auc_1: 0.8199 - val_recall_1: 0.2347 - val_precision_1: 0.5090 - val_hamming_loss: 0.7653\n","Epoch 7/10\n","1000/1000 [==============================] - 25s 25ms/step - loss: 1.7580 - acc: 0.4321 - auc_1: 0.8752 - recall_1: 0.2663 - precision_1: 0.6911 - hamming_loss: 0.7337 - val_loss: 1.9294 - val_acc: 0.3830 - val_auc_1: 0.8511 - val_recall_1: 0.2003 - val_precision_1: 0.6151 - val_hamming_loss: 0.7997\n","Epoch 8/10\n","1000/1000 [==============================] - 25s 25ms/step - loss: 1.6864 - acc: 0.4579 - auc_1: 0.8863 - recall_1: 0.2953 - precision_1: 0.7006 - hamming_loss: 0.7047 - val_loss: 1.7607 - val_acc: 0.4470 - val_auc_1: 0.8774 - val_recall_1: 0.2547 - val_precision_1: 0.7140 - val_hamming_loss: 0.7453\n","Epoch 9/10\n","1000/1000 [==============================] - 25s 25ms/step - loss: 1.6464 - acc: 0.4665 - auc_1: 0.8926 - recall_1: 0.3161 - precision_1: 0.7079 - hamming_loss: 0.6839 - val_loss: 1.8099 - val_acc: 0.4397 - val_auc_1: 0.8751 - val_recall_1: 0.2713 - val_precision_1: 0.6639 - val_hamming_loss: 0.7287\n","Epoch 10/10\n","1000/1000 [==============================] - 25s 25ms/step - loss: 1.5934 - acc: 0.4850 - auc_1: 0.8999 - recall_1: 0.3340 - precision_1: 0.7133 - hamming_loss: 0.6660 - val_loss: 1.7969 - val_acc: 0.4337 - val_auc_1: 0.8771 - val_recall_1: 0.2793 - val_precision_1: 0.6704 - val_hamming_loss: 0.7207\n","94/94 [==============================] - 4s 25ms/step - loss: 1.8362 - acc: 0.4250 - auc_1: 0.8759 - recall_1: 0.2713 - precision_1: 0.6481 - hamming_loss: 0.7287\n","***********test accuracy is [1.8361589908599854, 0.42500001192092896, 0.875940203666687, 0.27133333683013916, 0.6480891704559326, 0.7286666631698608] ***************\n","***********train time is 744.5641435619997 ***************\n","*********** Fitting model for Batch size of 36 ***************\n","Epoch 1/10\n","667/667 [==============================] - 30s 37ms/step - loss: 6.1388 - acc: 0.1490 - auc_2: 0.6038 - recall_2: 0.0667 - precision_2: 0.1666 - hamming_loss: 0.9333 - val_loss: 2.8679 - val_acc: 0.1527 - val_auc_2: 0.6668 - val_recall_2: 0.0680 - val_precision_2: 0.2612 - val_hamming_loss: 0.9320\n","Epoch 2/10\n","667/667 [==============================] - 22s 33ms/step - loss: 2.4781 - acc: 0.2307 - auc_2: 0.7294 - recall_2: 0.0810 - precision_2: 0.4535 - hamming_loss: 0.9190 - val_loss: 2.5109 - val_acc: 0.2140 - val_auc_2: 0.7325 - val_recall_2: 0.0867 - val_precision_2: 0.4530 - val_hamming_loss: 0.9133\n","Epoch 3/10\n","667/667 [==============================] - 22s 33ms/step - loss: 2.2345 - acc: 0.2910 - auc_2: 0.7834 - recall_2: 0.1210 - precision_2: 0.5638 - hamming_loss: 0.8790 - val_loss: 2.3539 - val_acc: 0.2650 - val_auc_2: 0.7694 - val_recall_2: 0.1087 - val_precision_2: 0.4435 - val_hamming_loss: 0.8913\n","Epoch 4/10\n","667/667 [==============================] - 22s 33ms/step - loss: 2.0821 - acc: 0.3377 - auc_2: 0.8168 - recall_2: 0.1602 - precision_2: 0.6119 - hamming_loss: 0.8398 - val_loss: 2.1228 - val_acc: 0.3323 - val_auc_2: 0.8128 - val_recall_2: 0.1377 - val_precision_2: 0.5917 - val_hamming_loss: 0.8623\n","Epoch 5/10\n","667/667 [==============================] - 22s 33ms/step - loss: 1.9539 - acc: 0.3761 - auc_2: 0.8412 - recall_2: 0.1961 - precision_2: 0.6515 - hamming_loss: 0.8039 - val_loss: 2.0461 - val_acc: 0.3610 - val_auc_2: 0.8295 - val_recall_2: 0.1777 - val_precision_2: 0.6212 - val_hamming_loss: 0.8223\n","Epoch 6/10\n","667/667 [==============================] - 22s 33ms/step - loss: 1.8556 - acc: 0.4054 - auc_2: 0.8587 - recall_2: 0.2277 - precision_2: 0.6680 - hamming_loss: 0.7723 - val_loss: 2.0736 - val_acc: 0.3507 - val_auc_2: 0.8227 - val_recall_2: 0.1720 - val_precision_2: 0.6300 - val_hamming_loss: 0.8280\n","Epoch 7/10\n","667/667 [==============================] - 23s 34ms/step - loss: 1.7721 - acc: 0.4316 - auc_2: 0.8730 - recall_2: 0.2609 - precision_2: 0.6853 - hamming_loss: 0.7391 - val_loss: 1.8155 - val_acc: 0.4297 - val_auc_2: 0.8687 - val_recall_2: 0.2357 - val_precision_2: 0.6811 - val_hamming_loss: 0.7643\n","Epoch 8/10\n","667/667 [==============================] - 22s 33ms/step - loss: 1.6858 - acc: 0.4570 - auc_2: 0.8862 - recall_2: 0.2908 - precision_2: 0.6992 - hamming_loss: 0.7092 - val_loss: 1.6885 - val_acc: 0.4700 - val_auc_2: 0.8867 - val_recall_2: 0.2873 - val_precision_2: 0.7476 - val_hamming_loss: 0.7127\n","Epoch 9/10\n","667/667 [==============================] - 23s 34ms/step - loss: 1.6201 - acc: 0.4799 - auc_2: 0.8955 - recall_2: 0.3196 - precision_2: 0.7065 - hamming_loss: 0.6804 - val_loss: 1.8489 - val_acc: 0.4110 - val_auc_2: 0.8634 - val_recall_2: 0.2460 - val_precision_2: 0.6709 - val_hamming_loss: 0.7540\n","Epoch 10/10\n","667/667 [==============================] - 23s 34ms/step - loss: 1.5536 - acc: 0.4932 - auc_2: 0.9040 - recall_2: 0.3440 - precision_2: 0.7245 - hamming_loss: 0.6560 - val_loss: 2.0887 - val_acc: 0.4027 - val_auc_2: 0.8543 - val_recall_2: 0.2987 - val_precision_2: 0.5649 - val_hamming_loss: 0.7013\n","94/94 [==============================] - 2s 23ms/step - loss: 2.1631 - acc: 0.3900 - auc_2: 0.8459 - recall_2: 0.2837 - precision_2: 0.5389 - hamming_loss: 0.7163\n","***********test accuracy is [2.1631312370300293, 0.38999998569488525, 0.8459433913230896, 0.2836666703224182, 0.5389487147331238, 0.7163333296775818] ***************\n","***********train time is 975.1229102769997 ***************\n","*********** Fitting model for Batch size of 48 ***************\n","Epoch 1/10\n","500/500 [==============================] - 25s 39ms/step - loss: 7.4169 - acc: 0.1441 - auc_3: 0.5956 - recall_3: 0.0760 - precision_3: 0.1663 - hamming_loss: 0.9240 - val_loss: 2.6856 - val_acc: 0.2200 - val_auc_3: 0.6862 - val_recall_3: 0.0643 - val_precision_3: 0.4196 - val_hamming_loss: 0.9357\n","Epoch 2/10\n","500/500 [==============================] - 17s 34ms/step - loss: 2.5138 - acc: 0.2330 - auc_3: 0.7246 - recall_3: 0.0867 - precision_3: 0.4481 - hamming_loss: 0.9133 - val_loss: 2.3584 - val_acc: 0.2777 - val_auc_3: 0.7551 - val_recall_3: 0.1083 - val_precision_3: 0.5399 - val_hamming_loss: 0.8917\n","Epoch 3/10\n","500/500 [==============================] - 17s 34ms/step - loss: 2.2478 - acc: 0.2922 - auc_3: 0.7821 - recall_3: 0.1246 - precision_3: 0.5617 - hamming_loss: 0.8754 - val_loss: 2.1391 - val_acc: 0.3257 - val_auc_3: 0.8041 - val_recall_3: 0.1457 - val_precision_3: 0.5866 - val_hamming_loss: 0.8543\n","Epoch 4/10\n","500/500 [==============================] - 17s 34ms/step - loss: 2.0866 - acc: 0.3397 - auc_3: 0.8159 - recall_3: 0.1587 - precision_3: 0.6083 - hamming_loss: 0.8413 - val_loss: 2.0735 - val_acc: 0.3527 - val_auc_3: 0.8165 - val_recall_3: 0.1633 - val_precision_3: 0.6187 - val_hamming_loss: 0.8367\n","Epoch 5/10\n","500/500 [==============================] - 17s 34ms/step - loss: 1.9421 - acc: 0.3803 - auc_3: 0.8433 - recall_3: 0.2000 - precision_3: 0.6527 - hamming_loss: 0.8000 - val_loss: 2.0240 - val_acc: 0.3533 - val_auc_3: 0.8314 - val_recall_3: 0.1757 - val_precision_3: 0.6207 - val_hamming_loss: 0.8243\n","Epoch 6/10\n","500/500 [==============================] - 17s 34ms/step - loss: 1.8348 - acc: 0.4155 - auc_3: 0.8618 - recall_3: 0.2408 - precision_3: 0.6770 - hamming_loss: 0.7592 - val_loss: 1.9428 - val_acc: 0.3857 - val_auc_3: 0.8473 - val_recall_3: 0.2243 - val_precision_3: 0.6174 - val_hamming_loss: 0.7757\n","Epoch 7/10\n","500/500 [==============================] - 17s 34ms/step - loss: 1.7325 - acc: 0.4449 - auc_3: 0.8782 - recall_3: 0.2745 - precision_3: 0.6974 - hamming_loss: 0.7255 - val_loss: 1.8638 - val_acc: 0.4197 - val_auc_3: 0.8603 - val_recall_3: 0.2403 - val_precision_3: 0.6776 - val_hamming_loss: 0.7597\n","Epoch 8/10\n","500/500 [==============================] - 18s 36ms/step - loss: 1.6441 - acc: 0.4727 - auc_3: 0.8909 - recall_3: 0.3081 - precision_3: 0.7116 - hamming_loss: 0.6919 - val_loss: 1.8290 - val_acc: 0.4357 - val_auc_3: 0.8708 - val_recall_3: 0.2877 - val_precision_3: 0.6383 - val_hamming_loss: 0.7123\n","Epoch 9/10\n","500/500 [==============================] - 18s 36ms/step - loss: 1.5605 - acc: 0.4983 - auc_3: 0.9026 - recall_3: 0.3383 - precision_3: 0.7240 - hamming_loss: 0.6618 - val_loss: 1.8505 - val_acc: 0.4267 - val_auc_3: 0.8694 - val_recall_3: 0.2997 - val_precision_3: 0.6340 - val_hamming_loss: 0.7003\n","Epoch 10/10\n","500/500 [==============================] - 17s 34ms/step - loss: 1.4984 - acc: 0.5137 - auc_3: 0.9106 - recall_3: 0.3668 - precision_3: 0.7315 - hamming_loss: 0.6332 - val_loss: 1.9430 - val_acc: 0.4300 - val_auc_3: 0.8566 - val_recall_3: 0.3160 - val_precision_3: 0.6380 - val_hamming_loss: 0.6840\n","94/94 [==============================] - 2s 25ms/step - loss: 2.0235 - acc: 0.4167 - auc_3: 0.8476 - recall_3: 0.3167 - precision_3: 0.6137 - hamming_loss: 0.6833\n","***********test accuracy is [2.0235233306884766, 0.4166666567325592, 0.8475922346115112, 0.3166666626930237, 0.6136950850486755, 0.6833333373069763] ***************\n","***********train time is 1155.1895343139995 ***************\n","*********** Fitting model for Batch size of 60 ***************\n","Epoch 1/10\n","400/400 [==============================] - 22s 39ms/step - loss: 7.3571 - acc: 0.1419 - auc_4: 0.5889 - recall_4: 0.0685 - precision_4: 0.1545 - hamming_loss: 0.9315 - val_loss: 2.7456 - val_acc: 0.1923 - val_auc_4: 0.6778 - val_recall_4: 0.0670 - val_precision_4: 0.3564 - val_hamming_loss: 0.9330\n","Epoch 2/10\n","400/400 [==============================] - 14s 36ms/step - loss: 2.5347 - acc: 0.2231 - auc_4: 0.7157 - recall_4: 0.0755 - precision_4: 0.4485 - hamming_loss: 0.9245 - val_loss: 2.4149 - val_acc: 0.2277 - val_auc_4: 0.7444 - val_recall_4: 0.0763 - val_precision_4: 0.4544 - val_hamming_loss: 0.9237\n","Epoch 3/10\n","400/400 [==============================] - 14s 36ms/step - loss: 2.2572 - acc: 0.2879 - auc_4: 0.7768 - recall_4: 0.1104 - precision_4: 0.5668 - hamming_loss: 0.8896 - val_loss: 2.2960 - val_acc: 0.2783 - val_auc_4: 0.7742 - val_recall_4: 0.1257 - val_precision_4: 0.5472 - val_hamming_loss: 0.8743\n","Epoch 4/10\n","400/400 [==============================] - 16s 39ms/step - loss: 2.0923 - acc: 0.3368 - auc_4: 0.8136 - recall_4: 0.1547 - precision_4: 0.6149 - hamming_loss: 0.8453 - val_loss: 2.1612 - val_acc: 0.3203 - val_auc_4: 0.8071 - val_recall_4: 0.1527 - val_precision_4: 0.5531 - val_hamming_loss: 0.8473\n","Epoch 5/10\n","400/400 [==============================] - 15s 39ms/step - loss: 1.9655 - acc: 0.3767 - auc_4: 0.8377 - recall_4: 0.1918 - precision_4: 0.6574 - hamming_loss: 0.8082 - val_loss: 1.9697 - val_acc: 0.3850 - val_auc_4: 0.8393 - val_recall_4: 0.1710 - val_precision_4: 0.6469 - val_hamming_loss: 0.8290\n","Epoch 6/10\n","400/400 [==============================] - 14s 36ms/step - loss: 1.8447 - acc: 0.4094 - auc_4: 0.8593 - recall_4: 0.2306 - precision_4: 0.6821 - hamming_loss: 0.7694 - val_loss: 2.0257 - val_acc: 0.3623 - val_auc_4: 0.8321 - val_recall_4: 0.1957 - val_precision_4: 0.6231 - val_hamming_loss: 0.8043\n","Epoch 7/10\n","400/400 [==============================] - 14s 36ms/step - loss: 1.7479 - acc: 0.4403 - auc_4: 0.8748 - recall_4: 0.2635 - precision_4: 0.7018 - hamming_loss: 0.7365 - val_loss: 1.9998 - val_acc: 0.3990 - val_auc_4: 0.8422 - val_recall_4: 0.2530 - val_precision_4: 0.6278 - val_hamming_loss: 0.7470\n","Epoch 8/10\n","400/400 [==============================] - 14s 36ms/step - loss: 1.6579 - acc: 0.4683 - auc_4: 0.8883 - recall_4: 0.2979 - precision_4: 0.7223 - hamming_loss: 0.7021 - val_loss: 1.8335 - val_acc: 0.4320 - val_auc_4: 0.8668 - val_recall_4: 0.2583 - val_precision_4: 0.6469 - val_hamming_loss: 0.7417\n","Epoch 9/10\n","400/400 [==============================] - 16s 39ms/step - loss: 1.5802 - acc: 0.4947 - auc_4: 0.8989 - recall_4: 0.3271 - precision_4: 0.7358 - hamming_loss: 0.6729 - val_loss: 1.7249 - val_acc: 0.4530 - val_auc_4: 0.8821 - val_recall_4: 0.2880 - val_precision_4: 0.6957 - val_hamming_loss: 0.7120\n","Epoch 10/10\n","400/400 [==============================] - 15s 39ms/step - loss: 1.5014 - acc: 0.5145 - auc_4: 0.9096 - recall_4: 0.3560 - precision_4: 0.7495 - hamming_loss: 0.6440 - val_loss: 1.8645 - val_acc: 0.4273 - val_auc_4: 0.8639 - val_recall_4: 0.2713 - val_precision_4: 0.6875 - val_hamming_loss: 0.7287\n","94/94 [==============================] - 4s 25ms/step - loss: 1.9167 - acc: 0.4147 - auc_4: 0.8573 - recall_4: 0.2627 - precision_4: 0.6502 - hamming_loss: 0.7373\n","***********test accuracy is [1.9166624546051025, 0.41466665267944336, 0.857344925403595, 0.2626666724681854, 0.6501650214195251, 0.737333357334137] ***************\n","***********train time is 1310.0193904729992 ***************\n","*********** Fitting model for Batch size of 72 ***************\n","Epoch 1/10\n","334/334 [==============================] - 20s 43ms/step - loss: 8.7229 - acc: 0.1416 - auc_5: 0.5847 - recall_5: 0.0815 - precision_5: 0.1546 - hamming_loss: 0.9185 - val_loss: 3.1626 - val_acc: 0.1767 - val_auc_5: 0.6408 - val_recall_5: 0.0757 - val_precision_5: 0.2762 - val_hamming_loss: 0.9243\n","Epoch 2/10\n","334/334 [==============================] - 13s 39ms/step - loss: 2.6038 - acc: 0.2228 - auc_5: 0.7094 - recall_5: 0.0832 - precision_5: 0.4252 - hamming_loss: 0.9168 - val_loss: 3.0412 - val_acc: 0.2160 - val_auc_5: 0.6747 - val_recall_5: 0.1117 - val_precision_5: 0.3357 - val_hamming_loss: 0.8883\n","Epoch 3/10\n","334/334 [==============================] - 13s 39ms/step - loss: 2.2900 - acc: 0.2850 - auc_5: 0.7734 - recall_5: 0.1182 - precision_5: 0.5351 - hamming_loss: 0.8817 - val_loss: 2.5124 - val_acc: 0.2743 - val_auc_5: 0.7400 - val_recall_5: 0.1383 - val_precision_5: 0.5273 - val_hamming_loss: 0.8617\n","Epoch 4/10\n","334/334 [==============================] - 13s 39ms/step - loss: 2.1032 - acc: 0.3375 - auc_5: 0.8114 - recall_5: 0.1596 - precision_5: 0.6109 - hamming_loss: 0.8404 - val_loss: 2.5416 - val_acc: 0.2580 - val_auc_5: 0.7600 - val_recall_5: 0.1513 - val_precision_5: 0.4177 - val_hamming_loss: 0.8487\n","Epoch 5/10\n","334/334 [==============================] - 13s 39ms/step - loss: 1.9518 - acc: 0.3828 - auc_5: 0.8406 - recall_5: 0.2048 - precision_5: 0.6615 - hamming_loss: 0.7952 - val_loss: 2.1296 - val_acc: 0.3650 - val_auc_5: 0.8189 - val_recall_5: 0.2030 - val_precision_5: 0.5702 - val_hamming_loss: 0.7970\n","Epoch 6/10\n","334/334 [==============================] - 13s 39ms/step - loss: 1.8397 - acc: 0.4128 - auc_5: 0.8610 - recall_5: 0.2384 - precision_5: 0.6739 - hamming_loss: 0.7616 - val_loss: 2.2804 - val_acc: 0.3183 - val_auc_5: 0.8069 - val_recall_5: 0.2053 - val_precision_5: 0.4783 - val_hamming_loss: 0.7947\n","Epoch 7/10\n","334/334 [==============================] - 13s 39ms/step - loss: 1.7255 - acc: 0.4531 - auc_5: 0.8787 - recall_5: 0.2785 - precision_5: 0.7058 - hamming_loss: 0.7215 - val_loss: 2.0891 - val_acc: 0.3837 - val_auc_5: 0.8376 - val_recall_5: 0.2537 - val_precision_5: 0.5325 - val_hamming_loss: 0.7463\n","Epoch 8/10\n","334/334 [==============================] - 13s 39ms/step - loss: 1.6351 - acc: 0.4777 - auc_5: 0.8918 - recall_5: 0.3120 - precision_5: 0.7173 - hamming_loss: 0.6880 - val_loss: 2.0104 - val_acc: 0.3973 - val_auc_5: 0.8475 - val_recall_5: 0.2703 - val_precision_5: 0.5764 - val_hamming_loss: 0.7297\n","Epoch 9/10\n","334/334 [==============================] - 13s 39ms/step - loss: 1.5531 - acc: 0.5004 - auc_5: 0.9033 - recall_5: 0.3414 - precision_5: 0.7321 - hamming_loss: 0.6586 - val_loss: 2.0672 - val_acc: 0.4097 - val_auc_5: 0.8449 - val_recall_5: 0.2957 - val_precision_5: 0.5561 - val_hamming_loss: 0.7043\n","Epoch 10/10\n","334/334 [==============================] - 13s 39ms/step - loss: 1.4738 - acc: 0.5255 - auc_5: 0.9131 - recall_5: 0.3745 - precision_5: 0.7454 - hamming_loss: 0.6255 - val_loss: 2.3894 - val_acc: 0.3560 - val_auc_5: 0.8156 - val_recall_5: 0.2613 - val_precision_5: 0.4971 - val_hamming_loss: 0.7387\n","94/94 [==============================] - 2s 24ms/step - loss: 2.4327 - acc: 0.3550 - auc_5: 0.8112 - recall_5: 0.2613 - precision_5: 0.4971 - hamming_loss: 0.7387\n","***********test accuracy is [2.4326963424682617, 0.35499998927116394, 0.8111903667449951, 0.2613333463668823, 0.49714648723602295, 0.7386666536331177] ***************\n","***********train time is 1447.313046941999 ***************\n","*********** Fitting model for Batch size of 84 ***************\n","Epoch 1/10\n","286/286 [==============================] - 20s 49ms/step - loss: 9.2014 - acc: 0.1296 - auc_6: 0.5742 - recall_6: 0.0797 - precision_6: 0.1406 - hamming_loss: 0.9203 - val_loss: 3.1171 - val_acc: 0.1817 - val_auc_6: 0.6455 - val_recall_6: 0.0707 - val_precision_6: 0.3131 - val_hamming_loss: 0.9293\n","Epoch 2/10\n","286/286 [==============================] - 13s 44ms/step - loss: 2.7151 - acc: 0.2115 - auc_6: 0.6954 - recall_6: 0.0817 - precision_6: 0.3826 - hamming_loss: 0.9183 - val_loss: 2.4344 - val_acc: 0.2540 - val_auc_6: 0.7393 - val_recall_6: 0.0900 - val_precision_6: 0.4770 - val_hamming_loss: 0.9100\n","Epoch 3/10\n","286/286 [==============================] - 12s 43ms/step - loss: 2.3272 - acc: 0.2879 - auc_6: 0.7655 - recall_6: 0.1184 - precision_6: 0.5424 - hamming_loss: 0.8816 - val_loss: 2.4049 - val_acc: 0.2753 - val_auc_6: 0.7565 - val_recall_6: 0.1177 - val_precision_6: 0.4889 - val_hamming_loss: 0.8823\n","Epoch 4/10\n","286/286 [==============================] - 13s 44ms/step - loss: 2.1257 - acc: 0.3363 - auc_6: 0.8068 - recall_6: 0.1546 - precision_6: 0.6162 - hamming_loss: 0.8454 - val_loss: 2.2321 - val_acc: 0.3100 - val_auc_6: 0.7904 - val_recall_6: 0.1547 - val_precision_6: 0.5570 - val_hamming_loss: 0.8453\n","Epoch 5/10\n","286/286 [==============================] - 13s 44ms/step - loss: 1.9727 - acc: 0.3839 - auc_6: 0.8366 - recall_6: 0.1992 - precision_6: 0.6512 - hamming_loss: 0.8008 - val_loss: 2.1053 - val_acc: 0.3503 - val_auc_6: 0.8230 - val_recall_6: 0.1967 - val_precision_6: 0.5695 - val_hamming_loss: 0.8033\n","Epoch 6/10\n","286/286 [==============================] - 12s 44ms/step - loss: 1.8528 - acc: 0.4132 - auc_6: 0.8578 - recall_6: 0.2360 - precision_6: 0.6773 - hamming_loss: 0.7640 - val_loss: 2.2179 - val_acc: 0.3490 - val_auc_6: 0.8132 - val_recall_6: 0.2087 - val_precision_6: 0.5199 - val_hamming_loss: 0.7913\n","Epoch 7/10\n","286/286 [==============================] - 12s 43ms/step - loss: 1.7409 - acc: 0.4452 - auc_6: 0.8757 - recall_6: 0.2714 - precision_6: 0.6950 - hamming_loss: 0.7286 - val_loss: 2.1156 - val_acc: 0.3477 - val_auc_6: 0.8312 - val_recall_6: 0.2133 - val_precision_6: 0.5182 - val_hamming_loss: 0.7867\n","Epoch 8/10\n","286/286 [==============================] - 12s 43ms/step - loss: 1.6418 - acc: 0.4725 - auc_6: 0.8906 - recall_6: 0.3042 - precision_6: 0.7226 - hamming_loss: 0.6958 - val_loss: 2.0371 - val_acc: 0.4187 - val_auc_6: 0.8462 - val_recall_6: 0.3047 - val_precision_6: 0.5982 - val_hamming_loss: 0.6953\n","Epoch 9/10\n","286/286 [==============================] - 12s 44ms/step - loss: 1.5543 - acc: 0.5032 - auc_6: 0.9024 - recall_6: 0.3374 - precision_6: 0.7402 - hamming_loss: 0.6626 - val_loss: 2.0570 - val_acc: 0.4043 - val_auc_6: 0.8506 - val_recall_6: 0.2870 - val_precision_6: 0.5657 - val_hamming_loss: 0.7130\n","Epoch 10/10\n","286/286 [==============================] - 12s 43ms/step - loss: 1.4856 - acc: 0.5233 - auc_6: 0.9113 - recall_6: 0.3673 - precision_6: 0.7504 - hamming_loss: 0.6327 - val_loss: 2.0915 - val_acc: 0.3910 - val_auc_6: 0.8443 - val_recall_6: 0.2913 - val_precision_6: 0.5560 - val_hamming_loss: 0.7087\n","94/94 [==============================] - 2s 25ms/step - loss: 2.1368 - acc: 0.3857 - auc_6: 0.8411 - recall_6: 0.2773 - precision_6: 0.5385 - hamming_loss: 0.7227\n","***********test accuracy is [2.1367733478546143, 0.3856666684150696, 0.8410951495170593, 0.2773333191871643, 0.538511335849762, 0.7226666808128357] ***************\n","***********train time is 1579.202323743999 ***************\n","*********** Fitting model for Batch size of 96 ***************\n","Epoch 1/10\n","250/250 [==============================] - 19s 51ms/step - loss: 9.8934 - acc: 0.1298 - auc_7: 0.5736 - recall_7: 0.0837 - precision_7: 0.1399 - hamming_loss: 0.9163 - val_loss: 2.6197 - val_acc: 0.2063 - val_auc_7: 0.7009 - val_recall_7: 0.0580 - val_precision_7: 0.4018 - val_hamming_loss: 0.9420\n","Epoch 2/10\n","250/250 [==============================] - 11s 45ms/step - loss: 2.7275 - acc: 0.2106 - auc_7: 0.6951 - recall_7: 0.0845 - precision_7: 0.3823 - hamming_loss: 0.9155 - val_loss: 2.5454 - val_acc: 0.2297 - val_auc_7: 0.7237 - val_recall_7: 0.0920 - val_precision_7: 0.4272 - val_hamming_loss: 0.9080\n","Epoch 3/10\n","250/250 [==============================] - 11s 45ms/step - loss: 2.3281 - acc: 0.2860 - auc_7: 0.7664 - recall_7: 0.1226 - precision_7: 0.5553 - hamming_loss: 0.8774 - val_loss: 2.2329 - val_acc: 0.3013 - val_auc_7: 0.7859 - val_recall_7: 0.1310 - val_precision_7: 0.5289 - val_hamming_loss: 0.8690\n","Epoch 4/10\n","250/250 [==============================] - 11s 45ms/step - loss: 2.1254 - acc: 0.3354 - auc_7: 0.8074 - recall_7: 0.1583 - precision_7: 0.6170 - hamming_loss: 0.8418 - val_loss: 2.2555 - val_acc: 0.3157 - val_auc_7: 0.7853 - val_recall_7: 0.1603 - val_precision_7: 0.5754 - val_hamming_loss: 0.8397\n","Epoch 5/10\n","250/250 [==============================] - 11s 45ms/step - loss: 1.9630 - acc: 0.3842 - auc_7: 0.8377 - recall_7: 0.2004 - precision_7: 0.6663 - hamming_loss: 0.7996 - val_loss: 2.1856 - val_acc: 0.3567 - val_auc_7: 0.8066 - val_recall_7: 0.1993 - val_precision_7: 0.5604 - val_hamming_loss: 0.8007\n","Epoch 6/10\n","250/250 [==============================] - 11s 45ms/step - loss: 1.8380 - acc: 0.4223 - auc_7: 0.8601 - recall_7: 0.2412 - precision_7: 0.6853 - hamming_loss: 0.7588 - val_loss: 1.9741 - val_acc: 0.3860 - val_auc_7: 0.8427 - val_recall_7: 0.2027 - val_precision_7: 0.6217 - val_hamming_loss: 0.7973\n","Epoch 7/10\n","250/250 [==============================] - 11s 45ms/step - loss: 1.7246 - acc: 0.4529 - auc_7: 0.8777 - recall_7: 0.2793 - precision_7: 0.7131 - hamming_loss: 0.7207 - val_loss: 2.0108 - val_acc: 0.3967 - val_auc_7: 0.8400 - val_recall_7: 0.2347 - val_precision_7: 0.6241 - val_hamming_loss: 0.7653\n","Epoch 8/10\n","250/250 [==============================] - 11s 45ms/step - loss: 1.6370 - acc: 0.4789 - auc_7: 0.8910 - recall_7: 0.3079 - precision_7: 0.7257 - hamming_loss: 0.6921 - val_loss: 1.9801 - val_acc: 0.3920 - val_auc_7: 0.8437 - val_recall_7: 0.2367 - val_precision_7: 0.6396 - val_hamming_loss: 0.7633\n","Epoch 9/10\n","250/250 [==============================] - 11s 45ms/step - loss: 1.5391 - acc: 0.5117 - auc_7: 0.9042 - recall_7: 0.3485 - precision_7: 0.7433 - hamming_loss: 0.6515 - val_loss: 1.7404 - val_acc: 0.4553 - val_auc_7: 0.8820 - val_recall_7: 0.2920 - val_precision_7: 0.6572 - val_hamming_loss: 0.7080\n","Epoch 10/10\n","250/250 [==============================] - 11s 45ms/step - loss: 1.4674 - acc: 0.5335 - auc_7: 0.9133 - recall_7: 0.3746 - precision_7: 0.7579 - hamming_loss: 0.6254 - val_loss: 1.8551 - val_acc: 0.4587 - val_auc_7: 0.8684 - val_recall_7: 0.3007 - val_precision_7: 0.6777 - val_hamming_loss: 0.6993\n","94/94 [==============================] - 2s 25ms/step - loss: 1.9086 - acc: 0.4303 - auc_7: 0.8617 - recall_7: 0.2897 - precision_7: 0.6447 - hamming_loss: 0.7103\n","***********test accuracy is [1.9086098670959473, 0.43033334612846375, 0.8616611957550049, 0.28966665267944336, 0.6446587443351746, 0.7103333473205566] ***************\n","***********train time is 1699.1332931649981 ***************\n","*********** Fitting model for Batch size of 108 ***************\n","Epoch 1/10\n","223/223 [==============================] - 19s 57ms/step - loss: 10.8521 - acc: 0.1248 - auc_8: 0.5686 - recall_8: 0.0822 - precision_8: 0.1300 - hamming_loss: 0.9178 - val_loss: 3.8729 - val_acc: 0.1263 - val_auc_8: 0.6050 - val_recall_8: 0.0827 - val_precision_8: 0.1703 - val_hamming_loss: 0.9173\n","Epoch 2/10\n","223/223 [==============================] - 11s 50ms/step - loss: 2.8501 - acc: 0.2044 - auc_8: 0.6792 - recall_8: 0.0821 - precision_8: 0.3640 - hamming_loss: 0.9179 - val_loss: 3.1377 - val_acc: 0.1717 - val_auc_8: 0.6693 - val_recall_8: 0.0953 - val_precision_8: 0.2263 - val_hamming_loss: 0.9047\n","Epoch 3/10\n","223/223 [==============================] - 11s 50ms/step - loss: 2.3934 - acc: 0.2687 - auc_8: 0.7513 - recall_8: 0.1113 - precision_8: 0.5119 - hamming_loss: 0.8887 - val_loss: 2.5660 - val_acc: 0.2390 - val_auc_8: 0.7408 - val_recall_8: 0.1127 - val_precision_8: 0.3930 - val_hamming_loss: 0.8873\n","Epoch 4/10\n","223/223 [==============================] - 11s 51ms/step - loss: 2.1574 - acc: 0.3250 - auc_8: 0.8000 - recall_8: 0.1495 - precision_8: 0.6008 - hamming_loss: 0.8505 - val_loss: 2.4814 - val_acc: 0.2780 - val_auc_8: 0.7626 - val_recall_8: 0.1397 - val_precision_8: 0.4293 - val_hamming_loss: 0.8603\n","Epoch 5/10\n","223/223 [==============================] - 11s 50ms/step - loss: 1.9990 - acc: 0.3719 - auc_8: 0.8315 - recall_8: 0.1910 - precision_8: 0.6504 - hamming_loss: 0.8090 - val_loss: 2.4476 - val_acc: 0.3207 - val_auc_8: 0.7780 - val_recall_8: 0.1873 - val_precision_8: 0.5000 - val_hamming_loss: 0.8127\n","Epoch 6/10\n","223/223 [==============================] - 11s 50ms/step - loss: 1.8776 - acc: 0.4095 - auc_8: 0.8532 - recall_8: 0.2270 - precision_8: 0.6778 - hamming_loss: 0.7730 - val_loss: 2.6319 - val_acc: 0.2837 - val_auc_8: 0.7701 - val_recall_8: 0.1960 - val_precision_8: 0.3858 - val_hamming_loss: 0.8040\n","Epoch 7/10\n","223/223 [==============================] - 11s 50ms/step - loss: 1.7526 - acc: 0.4455 - auc_8: 0.8731 - recall_8: 0.2708 - precision_8: 0.7088 - hamming_loss: 0.7292 - val_loss: 2.3898 - val_acc: 0.3063 - val_auc_8: 0.7973 - val_recall_8: 0.2113 - val_precision_8: 0.4056 - val_hamming_loss: 0.7887\n","Epoch 8/10\n","223/223 [==============================] - 11s 51ms/step - loss: 1.6492 - acc: 0.4756 - auc_8: 0.8889 - recall_8: 0.3040 - precision_8: 0.7257 - hamming_loss: 0.6960 - val_loss: 2.0565 - val_acc: 0.3883 - val_auc_8: 0.8369 - val_recall_8: 0.2577 - val_precision_8: 0.5751 - val_hamming_loss: 0.7423\n","Epoch 9/10\n","223/223 [==============================] - 11s 50ms/step - loss: 1.5648 - acc: 0.5015 - auc_8: 0.9007 - recall_8: 0.3372 - precision_8: 0.7343 - hamming_loss: 0.6628 - val_loss: 2.2914 - val_acc: 0.3723 - val_auc_8: 0.8319 - val_recall_8: 0.2887 - val_precision_8: 0.4951 - val_hamming_loss: 0.7113\n","Epoch 10/10\n","223/223 [==============================] - 11s 51ms/step - loss: 1.4966 - acc: 0.5232 - auc_8: 0.9095 - recall_8: 0.3660 - precision_8: 0.7516 - hamming_loss: 0.6340 - val_loss: 1.8713 - val_acc: 0.4433 - val_auc_8: 0.8652 - val_recall_8: 0.3047 - val_precision_8: 0.6387 - val_hamming_loss: 0.6953\n","94/94 [==============================] - 3s 27ms/step - loss: 1.9321 - acc: 0.4300 - auc_8: 0.8587 - recall_8: 0.2980 - precision_8: 0.6243 - hamming_loss: 0.7020\n","***********test accuracy is [1.932084321975708, 0.4300000071525574, 0.858693540096283, 0.2980000078678131, 0.6243016719818115, 0.7020000219345093] ***************\n","***********train time is 1818.4600775489985 ***************\n","*********** Fitting model for Batch size of 120 ***************\n","Epoch 1/10\n","200/200 [==============================] - 18s 60ms/step - loss: 10.3793 - acc: 0.1260 - auc_9: 0.5667 - recall_9: 0.0849 - precision_9: 0.1354 - hamming_loss: 0.9151 - val_loss: 3.8393 - val_acc: 0.1543 - val_auc_9: 0.6145 - val_recall_9: 0.0717 - val_precision_9: 0.2207 - val_hamming_loss: 0.9283\n","Epoch 2/10\n","200/200 [==============================] - 10s 53ms/step - loss: 2.8906 - acc: 0.2024 - auc_9: 0.6747 - recall_9: 0.0803 - precision_9: 0.3576 - hamming_loss: 0.9197 - val_loss: 2.3950 - val_acc: 0.2397 - val_auc_9: 0.7368 - val_recall_9: 0.0833 - val_precision_9: 0.5841 - val_hamming_loss: 0.9167\n","Epoch 3/10\n","200/200 [==============================] - 10s 52ms/step - loss: 2.3997 - acc: 0.2630 - auc_9: 0.7494 - recall_9: 0.1044 - precision_9: 0.5089 - hamming_loss: 0.8956 - val_loss: 2.2962 - val_acc: 0.2987 - val_auc_9: 0.7661 - val_recall_9: 0.1137 - val_precision_9: 0.6122 - val_hamming_loss: 0.8863\n","Epoch 4/10\n","200/200 [==============================] - 11s 53ms/step - loss: 2.1791 - acc: 0.3217 - auc_9: 0.7940 - recall_9: 0.1411 - precision_9: 0.6025 - hamming_loss: 0.8589 - val_loss: 2.2831 - val_acc: 0.2960 - val_auc_9: 0.7783 - val_recall_9: 0.1483 - val_precision_9: 0.5583 - val_hamming_loss: 0.8517\n","Epoch 5/10\n","200/200 [==============================] - 11s 53ms/step - loss: 2.0172 - acc: 0.3708 - auc_9: 0.8269 - recall_9: 0.1857 - precision_9: 0.6489 - hamming_loss: 0.8143 - val_loss: 2.0433 - val_acc: 0.3717 - val_auc_9: 0.8245 - val_recall_9: 0.1880 - val_precision_9: 0.6402 - val_hamming_loss: 0.8120\n","Epoch 6/10\n","200/200 [==============================] - 10s 52ms/step - loss: 1.8827 - acc: 0.4067 - auc_9: 0.8510 - recall_9: 0.2225 - precision_9: 0.6877 - hamming_loss: 0.7775 - val_loss: 2.0255 - val_acc: 0.3857 - val_auc_9: 0.8296 - val_recall_9: 0.2053 - val_precision_9: 0.6331 - val_hamming_loss: 0.7947\n","Epoch 7/10\n","200/200 [==============================] - 10s 52ms/step - loss: 1.7659 - acc: 0.4405 - auc_9: 0.8708 - recall_9: 0.2614 - precision_9: 0.7053 - hamming_loss: 0.7386 - val_loss: 1.8782 - val_acc: 0.4210 - val_auc_9: 0.8569 - val_recall_9: 0.2360 - val_precision_9: 0.6827 - val_hamming_loss: 0.7640\n","Epoch 8/10\n","200/200 [==============================] - 10s 52ms/step - loss: 1.6665 - acc: 0.4744 - auc_9: 0.8856 - recall_9: 0.2971 - precision_9: 0.7327 - hamming_loss: 0.7029 - val_loss: 1.7649 - val_acc: 0.4627 - val_auc_9: 0.8731 - val_recall_9: 0.2853 - val_precision_9: 0.6965 - val_hamming_loss: 0.7147\n","Epoch 9/10\n","200/200 [==============================] - 10s 52ms/step - loss: 1.5720 - acc: 0.5037 - auc_9: 0.8993 - recall_9: 0.3323 - precision_9: 0.7417 - hamming_loss: 0.6677 - val_loss: 1.7556 - val_acc: 0.4597 - val_auc_9: 0.8778 - val_recall_9: 0.3107 - val_precision_9: 0.6878 - val_hamming_loss: 0.6893\n","Epoch 10/10\n","200/200 [==============================] - 10s 52ms/step - loss: 1.4824 - acc: 0.5266 - auc_9: 0.9111 - recall_9: 0.3629 - precision_9: 0.7582 - hamming_loss: 0.6371 - val_loss: 1.7454 - val_acc: 0.4667 - val_auc_9: 0.8811 - val_recall_9: 0.3130 - val_precision_9: 0.6674 - val_hamming_loss: 0.6870\n","94/94 [==============================] - 4s 25ms/step - loss: 1.7900 - acc: 0.4647 - auc_9: 0.8761 - recall_9: 0.3223 - precision_9: 0.6538 - hamming_loss: 0.6777\n","***********test accuracy is [1.7899912595748901, 0.4646666646003723, 0.876144289970398, 0.32233333587646484, 0.6538201570510864, 0.6776666641235352] ***************\n","***********train time is 1930.0329600849982 ***************\n"]}],"source":["for i in [12, 24, 36, 48, 60, 72, 84, 96, 108, 120]:\n","  print(\"*********** Fitting model for Batch size of\", i ,\"***************\")\n","  model = compile_model()\n","  model.fit(X_train, y_train, batch_size = i, epochs=10, validation_data=(X_val, y_val), callbacks = [cb])\n","  test_acc = model.evaluate(X_test, y_test)\n","  print(\"***********test accuracy is\", test_acc,\"***************\")\n","  print(\"***********train time is\", sum(cb.logs),\"***************\")\n","  print(\"f1 score is\", sum(test_acc[6])/15)"]}]}