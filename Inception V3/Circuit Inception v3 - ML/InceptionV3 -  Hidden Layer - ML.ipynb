{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"InceptionV3 -  Hidden Layer - ML.ipynb","provenance":[],"authorship_tag":"ABX9TyNx4saDJd/xNdjiiKztQ0Zb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MfZr5GpLfV8M"},"source":["### Mounting drive on Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39730,"status":"ok","timestamp":1648911418896,"user":{"displayName":"Imp Makers","userId":"16307378287047438992"},"user_tz":-330},"id":"efjsRr4LAtas","outputId":"8a30a961-29c6-4757-ea07-9253ecbc8c80"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"yYQAlX3dFz2E"},"source":["###Libraries"]},{"cell_type":"code","source":["!pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XR_v6BD4p4nV","executionInfo":{"status":"ok","timestamp":1648911422846,"user_tz":-330,"elapsed":3954,"user":{"displayName":"Imp Makers","userId":"16307378287047438992"}},"outputId":"e86691dd-f2d6-4bc0-913e-6003fb0aebaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 19.1 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 604 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 634 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 686 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 716 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 747 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 768 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 798 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 829 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 849 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 880 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 931 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 942 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 962 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 993 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.16.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tBQUozfKF1sR"},"outputs":[],"source":["import os\n","import cv2\n","import os\n","import h5py\n","import numpy as np\n","import pickle\n","from tqdm import tqdm\n","from PIL import Image\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","os.chdir('/gdrive/My Drive/')\n","from numpy import savez_compressed\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageEnhance\n","import tensorflow_datasets as tfds\n","from tensorflow_addons.metrics import HammingLoss\n","from tensorflow_addons.metrics import F1Score\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.applications.inception_v3 import preprocess_input\n","from tensorflow.keras import layers, models\n","import tensorflow.keras as keras\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from keras.models import Sequential, load_model\n","from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model"]},{"cell_type":"markdown","metadata":{"id":"yezyzDK8k6I_"},"source":["## Effect of changing hidden layers\n","\n","\n","\n","In order to study the effects of changing number of hidden layers totl number of neurons must be kept constant across all layers while training the model. Therefore, the following experimental setup is used here:\n","\n","\n","For Ex: \n","        \n","        If number of neurons be = 1024\n","\n","        number of hidden layers = 1\n","\n","        \n","        If number of hidden layers = 2\n","\n","        Number of neurons per hidden layer are reduced to 512\n","\n","        \n","        Hence, Number of layers: [1, 2, 4, 8, 16, 32, 64]\n","\n","        Number of Neurons per layer: [1024, 512, 256, 128, 64, 32, 16] \n","\n"]},{"cell_type":"markdown","metadata":{"id":"Hsi_1RLAomg0"},"source":["### For ImageNet as a source"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W0z4UBAxLFGX"},"outputs":[],"source":["def compile_model(num_neurons, num_layers):\n","  \n","  from timeit import default_timer as timer\n","  class TimingCallback(keras.callbacks.Callback):\n","      def __init__(self, logs={}):\n","          self.logs=[]\n","      def on_epoch_begin(self, epoch, logs={}):\n","          self.starttime = timer()\n","      def on_epoch_end(self, epoch, logs={}):\n","          self.logs.append(timer()-self.starttime)\n","\n","  cb = TimingCallback()\n","\n","  from tensorflow.keras.applications.inception_v3 import InceptionV3\n","  pre_trained_model = InceptionV3(input_shape = (96, 96, 3), \n","                                include_top = False, \n","                                weights = 'None')\n","  #for layer in pre_trained_model.layers:\n","  #  layer.trainable = False\n","\n","  from tensorflow.keras.optimizers import RMSprop\n","\n","  # Flatten the output layer to 1 dimension\n","  x = layers.Flatten()(pre_trained_model.output)\n","\n","  for i in range(num_layers):\n","    # Add a fully connected layer with \"num_neurons\" hidden units and ReLU activation\n","    x = layers.Dense(num_neurons, activation='relu')(x)                  \n","  \n","  # Add a final sigmoid layer for classification\n","  x = layers.Dense  (15, activation='softmax')(x)           \n","\n","  model = Model( pre_trained_model.input, x) \n","\n","  model.compile(optimizer = RMSprop(lr=0.0001), \n","              loss = 'categorical_crossentropy', \n","              metrics = ['acc', tf.keras.metrics.AUC(), tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), HammingLoss(threshold=0.5, mode='multiclass'), F1Score(num_classes= 15, threshold=0.5)])\n","  return model, cb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXyqy_JoMvbV"},"outputs":[],"source":["data = np.load('Xtrain.npy', allow_pickle=True)\n","labels = np.load('ytrain.npy', allow_pickle=True)\n","\n","X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size = 0.2, random_state = 42, stratify = labels)\n","X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42, stratify = y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P2F6PdS3M1KT"},"outputs":[],"source":["y_train = to_categorical(y_train, 15)\n","y_val = to_categorical(y_val, 15)\n","y_test = to_categorical(y_test, 15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":164529,"status":"ok","timestamp":1648911596855,"user":{"displayName":"Imp Makers","userId":"16307378287047438992"},"user_tz":-330},"id":"yX4iehlJ0JfK","outputId":"4fd21c93-06d7-438d-be52-9e2acdb1067a"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 1024 neurons size and 1 hidden layers\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87916544/87910968 [==============================] - 1s 0us/step\n","87924736/87910968 [==============================] - 1s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 30s 60ms/step - loss: 24.1073 - acc: 0.1236 - auc: 0.5466 - recall: 0.1191 - precision: 0.1257 - hamming_loss: 0.8809 - f1_score: 0.1223 - val_loss: 13.8997 - val_acc: 0.1470 - val_auc: 0.5697 - val_recall: 0.1393 - val_precision: 0.1486 - val_hamming_loss: 0.8607 - val_f1_score: 0.1152\n","Epoch 2/10\n","200/200 [==============================] - 10s 51ms/step - loss: 16.1683 - acc: 0.1709 - auc: 0.5852 - recall: 0.1629 - precision: 0.1754 - hamming_loss: 0.8371 - f1_score: 0.1688 - val_loss: 17.3577 - val_acc: 0.1437 - val_auc: 0.5683 - val_recall: 0.1400 - val_precision: 0.1471 - val_hamming_loss: 0.8600 - val_f1_score: 0.1168\n","Epoch 3/10\n","200/200 [==============================] - 10s 51ms/step - loss: 13.0374 - acc: 0.2033 - auc: 0.6089 - recall: 0.1914 - precision: 0.2097 - hamming_loss: 0.8086 - f1_score: 0.1998 - val_loss: 12.3234 - val_acc: 0.2240 - val_auc: 0.6201 - val_recall: 0.2120 - val_precision: 0.2376 - val_hamming_loss: 0.7880 - val_f1_score: 0.1742\n","Epoch 4/10\n","200/200 [==============================] - 10s 52ms/step - loss: 11.3767 - acc: 0.2265 - auc: 0.6290 - recall: 0.2130 - precision: 0.2350 - hamming_loss: 0.7870 - f1_score: 0.2231 - val_loss: 11.3517 - val_acc: 0.2153 - val_auc: 0.6262 - val_recall: 0.2027 - val_precision: 0.2261 - val_hamming_loss: 0.7973 - val_f1_score: 0.1750\n","Epoch 5/10\n","200/200 [==============================] - 10s 52ms/step - loss: 10.0582 - acc: 0.2446 - auc: 0.6435 - recall: 0.2309 - precision: 0.2573 - hamming_loss: 0.7691 - f1_score: 0.2429 - val_loss: 12.0726 - val_acc: 0.2350 - val_auc: 0.6404 - val_recall: 0.2187 - val_precision: 0.2451 - val_hamming_loss: 0.7813 - val_f1_score: 0.1958\n","Epoch 6/10\n","200/200 [==============================] - 11s 53ms/step - loss: 9.1140 - acc: 0.2623 - auc: 0.6572 - recall: 0.2455 - precision: 0.2765 - hamming_loss: 0.7545 - f1_score: 0.2597 - val_loss: 8.9134 - val_acc: 0.2380 - val_auc: 0.6512 - val_recall: 0.2250 - val_precision: 0.2523 - val_hamming_loss: 0.7750 - val_f1_score: 0.2164\n","Epoch 7/10\n","200/200 [==============================] - 10s 52ms/step - loss: 8.0013 - acc: 0.2811 - auc: 0.6765 - recall: 0.2629 - precision: 0.2969 - hamming_loss: 0.7371 - f1_score: 0.2785 - val_loss: 8.1961 - val_acc: 0.2703 - val_auc: 0.6673 - val_recall: 0.2533 - val_precision: 0.2815 - val_hamming_loss: 0.7467 - val_f1_score: 0.2410\n","Epoch 8/10\n","200/200 [==============================] - 11s 54ms/step - loss: 7.2938 - acc: 0.2984 - auc: 0.6905 - recall: 0.2778 - precision: 0.3180 - hamming_loss: 0.7222 - f1_score: 0.2959 - val_loss: 7.1744 - val_acc: 0.3237 - val_auc: 0.7000 - val_recall: 0.2940 - val_precision: 0.3417 - val_hamming_loss: 0.7060 - val_f1_score: 0.2736\n","Epoch 9/10\n","200/200 [==============================] - 10s 53ms/step - loss: 6.7310 - acc: 0.3148 - auc: 0.7053 - recall: 0.2929 - precision: 0.3376 - hamming_loss: 0.7071 - f1_score: 0.3131 - val_loss: 8.4314 - val_acc: 0.2770 - val_auc: 0.6636 - val_recall: 0.2637 - val_precision: 0.2936 - val_hamming_loss: 0.7363 - val_f1_score: 0.2337\n","Epoch 10/10\n","200/200 [==============================] - 11s 54ms/step - loss: 6.1335 - acc: 0.3270 - auc: 0.7143 - recall: 0.3038 - precision: 0.3528 - hamming_loss: 0.6962 - f1_score: 0.3259 - val_loss: 6.1206 - val_acc: 0.2823 - val_auc: 0.7002 - val_recall: 0.2633 - val_precision: 0.2954 - val_hamming_loss: 0.7367 - val_f1_score: 0.2732\n","94/94 [==============================] - 6s 34ms/step - loss: 6.2907 - acc: 0.2797 - auc: 0.6955 - recall: 0.2590 - precision: 0.2900 - hamming_loss: 0.7410 - f1_score: 0.2651\n","***********test accuracy is [6.290703773498535, 0.2796666622161865, 0.6954583525657654, 0.2590000033378601, 0.29003360867500305, 0.7409999966621399, array([0.17557251, 0.22123894, 0.31982946, 0.4464286 , 0.1793722 ,\n","       0.5470589 , 0.2892562 , 0.17120624, 0.08928571, 0.07655502,\n","       0.36104512, 0.44444442, 0.40978593, 0.02955665, 0.21639346],\n","      dtype=float32)] ***************\n","***********train time is 124.06376287299975 ***************\n","f1 score is 0.26513528848687806\n"]}],"source":["print(\"*********** Fitting model for 1024 neurons size and 1 hidden layers\")\n","model, cb = compile_model(1024, 1)\n","model.fit(X_train, y_train, batch_size = 120, epochs=10, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"***********train time is\", sum(cb.logs),\"***************\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157559,"status":"ok","timestamp":1648911754404,"user":{"displayName":"Imp Makers","userId":"16307378287047438992"},"user_tz":-330},"id":"Lbhi4nFhM-xw","outputId":"30ab7b56-bcc5-43fa-8480-81b1d5b63fb9"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 512 dataset size and 2 hidden layers\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 18s 61ms/step - loss: 12.4618 - acc: 0.1295 - auc_1: 0.5588 - recall_1: 0.1123 - precision_1: 0.1321 - hamming_loss: 0.8877 - f1_score: 0.1211 - val_loss: 7.1850 - val_acc: 0.1583 - val_auc_1: 0.6014 - val_recall_1: 0.1290 - val_precision_1: 0.1771 - val_hamming_loss: 0.8710 - val_f1_score: 0.1169\n","Epoch 2/10\n","200/200 [==============================] - 11s 54ms/step - loss: 6.1773 - acc: 0.1773 - auc_1: 0.6187 - recall_1: 0.1419 - precision_1: 0.1941 - hamming_loss: 0.8581 - f1_score: 0.1634 - val_loss: 4.7471 - val_acc: 0.2177 - val_auc_1: 0.6536 - val_recall_1: 0.1700 - val_precision_1: 0.2434 - val_hamming_loss: 0.8300 - val_f1_score: 0.1754\n","Epoch 3/10\n","200/200 [==============================] - 11s 53ms/step - loss: 4.3335 - acc: 0.2243 - auc_1: 0.6731 - recall_1: 0.1706 - precision_1: 0.2673 - hamming_loss: 0.8294 - f1_score: 0.2068 - val_loss: 3.8846 - val_acc: 0.2327 - val_auc_1: 0.6818 - val_recall_1: 0.1670 - val_precision_1: 0.2909 - val_hamming_loss: 0.8330 - val_f1_score: 0.1812\n","Epoch 4/10\n","200/200 [==============================] - 11s 53ms/step - loss: 3.3840 - acc: 0.2659 - auc_1: 0.7202 - recall_1: 0.1926 - precision_1: 0.3426 - hamming_loss: 0.8074 - f1_score: 0.2439 - val_loss: 3.4924 - val_acc: 0.2607 - val_auc_1: 0.7062 - val_recall_1: 0.1910 - val_precision_1: 0.3343 - val_hamming_loss: 0.8090 - val_f1_score: 0.2121\n","Epoch 5/10\n","200/200 [==============================] - 11s 55ms/step - loss: 2.8340 - acc: 0.3079 - auc_1: 0.7585 - recall_1: 0.2128 - precision_1: 0.4129 - hamming_loss: 0.7872 - f1_score: 0.2774 - val_loss: 3.0140 - val_acc: 0.2917 - val_auc_1: 0.7522 - val_recall_1: 0.2097 - val_precision_1: 0.3769 - val_hamming_loss: 0.7903 - val_f1_score: 0.2512\n","Epoch 6/10\n","200/200 [==============================] - 11s 55ms/step - loss: 2.4731 - acc: 0.3442 - auc_1: 0.7936 - recall_1: 0.2342 - precision_1: 0.4746 - hamming_loss: 0.7657 - f1_score: 0.3090 - val_loss: 2.4019 - val_acc: 0.3697 - val_auc_1: 0.8006 - val_recall_1: 0.2307 - val_precision_1: 0.5134 - val_hamming_loss: 0.7693 - val_f1_score: 0.3042\n","Epoch 7/10\n","200/200 [==============================] - 11s 55ms/step - loss: 2.2363 - acc: 0.3804 - auc_1: 0.8199 - recall_1: 0.2587 - precision_1: 0.5342 - hamming_loss: 0.7413 - f1_score: 0.3432 - val_loss: 2.5219 - val_acc: 0.3450 - val_auc_1: 0.7942 - val_recall_1: 0.2317 - val_precision_1: 0.4472 - val_hamming_loss: 0.7683 - val_f1_score: 0.2880\n","Epoch 8/10\n","200/200 [==============================] - 11s 55ms/step - loss: 2.0278 - acc: 0.4131 - auc_1: 0.8444 - recall_1: 0.2830 - precision_1: 0.5840 - hamming_loss: 0.7170 - f1_score: 0.3754 - val_loss: 2.3286 - val_acc: 0.3893 - val_auc_1: 0.8170 - val_recall_1: 0.2547 - val_precision_1: 0.5159 - val_hamming_loss: 0.7453 - val_f1_score: 0.3255\n","Epoch 9/10\n","200/200 [==============================] - 11s 55ms/step - loss: 1.8749 - acc: 0.4457 - auc_1: 0.8635 - recall_1: 0.3143 - precision_1: 0.6266 - hamming_loss: 0.6857 - f1_score: 0.4126 - val_loss: 2.1066 - val_acc: 0.4277 - val_auc_1: 0.8402 - val_recall_1: 0.2797 - val_precision_1: 0.5743 - val_hamming_loss: 0.7203 - val_f1_score: 0.3562\n","Epoch 10/10\n","200/200 [==============================] - 11s 55ms/step - loss: 1.7639 - acc: 0.4693 - auc_1: 0.8783 - recall_1: 0.3307 - precision_1: 0.6510 - hamming_loss: 0.6693 - f1_score: 0.4324 - val_loss: 1.9819 - val_acc: 0.4613 - val_auc_1: 0.8588 - val_recall_1: 0.3180 - val_precision_1: 0.6289 - val_hamming_loss: 0.6820 - val_f1_score: 0.4019\n","94/94 [==============================] - 4s 27ms/step - loss: 2.0563 - acc: 0.4193 - auc_1: 0.8468 - recall_1: 0.2870 - precision_1: 0.5676 - hamming_loss: 0.7130 - f1_score: 0.3591\n","***********test accuracy is [2.056323528289795, 0.4193333387374878, 0.8468056321144104, 0.28700000047683716, 0.5675675868988037, 0.7129999995231628, array([0.32620323, 0.29718876, 0.22310759, 0.50119334, 0.5169713 ,\n","       0.6233062 , 0.45871562, 0.16814159, 0.34421363, 0.31128407,\n","       0.3508772 , 0.48421052, 0.4610169 , 0.18257262, 0.13698632],\n","      dtype=float32)] ***************\n","***********train time is 115.42108766200045 ***************\n","f1 score is 0.3590659250815709\n"]}],"source":["print(\"*********** Fitting model for 512 dataset size and 2 hidden layers\")\n","model, cb = compile_model(512, 2)\n","model.fit(X_train, y_train, batch_size = 120, epochs=10, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"***********train time is\", sum(cb.logs),\"***************\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":126340,"status":"ok","timestamp":1648911880726,"user":{"displayName":"Imp Makers","userId":"16307378287047438992"},"user_tz":-330},"id":"Z3JbrVRHwO_T","outputId":"87e49b86-ac15-406d-fed1-f92223b68453"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 256 dataset size and 4 hidden layers\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 17s 62ms/step - loss: 5.0816 - acc: 0.1280 - auc_2: 0.5820 - recall_2: 0.0635 - precision_2: 0.1416 - hamming_loss: 0.9365 - f1_score: 0.0868 - val_loss: 2.9854 - val_acc: 0.1743 - val_auc_2: 0.6556 - val_recall_2: 0.0587 - val_precision_2: 0.2785 - val_hamming_loss: 0.9413 - val_f1_score: 0.0890\n","Epoch 2/10\n","200/200 [==============================] - 11s 53ms/step - loss: 2.8623 - acc: 0.1961 - auc_2: 0.6802 - recall_2: 0.0735 - precision_2: 0.3209 - hamming_loss: 0.9265 - f1_score: 0.1163 - val_loss: 3.0074 - val_acc: 0.1720 - val_auc_2: 0.6714 - val_recall_2: 0.0780 - val_precision_2: 0.2505 - val_hamming_loss: 0.9220 - val_f1_score: 0.0862\n","Epoch 3/10\n","200/200 [==============================] - 11s 55ms/step - loss: 2.4660 - acc: 0.2519 - auc_2: 0.7394 - recall_2: 0.0897 - precision_2: 0.4615 - hamming_loss: 0.9103 - f1_score: 0.1451 - val_loss: 2.3429 - val_acc: 0.2947 - val_auc_2: 0.7598 - val_recall_2: 0.0947 - val_precision_2: 0.5338 - val_hamming_loss: 0.9053 - val_f1_score: 0.1508\n","Epoch 4/10\n","200/200 [==============================] - 11s 54ms/step - loss: 2.2463 - acc: 0.3030 - auc_2: 0.7819 - recall_2: 0.1147 - precision_2: 0.5555 - hamming_loss: 0.8852 - f1_score: 0.1836 - val_loss: 2.4083 - val_acc: 0.2620 - val_auc_2: 0.7620 - val_recall_2: 0.1147 - val_precision_2: 0.4439 - val_hamming_loss: 0.8853 - val_f1_score: 0.1677\n","Epoch 5/10\n","200/200 [==============================] - 11s 54ms/step - loss: 2.0989 - acc: 0.3410 - auc_2: 0.8112 - recall_2: 0.1427 - precision_2: 0.6276 - hamming_loss: 0.8573 - f1_score: 0.2252 - val_loss: 2.1677 - val_acc: 0.3370 - val_auc_2: 0.8016 - val_recall_2: 0.1320 - val_precision_2: 0.5764 - val_hamming_loss: 0.8680 - val_f1_score: 0.2051\n","Epoch 6/10\n","200/200 [==============================] - 11s 56ms/step - loss: 1.9850 - acc: 0.3733 - auc_2: 0.8334 - recall_2: 0.1699 - precision_2: 0.6656 - hamming_loss: 0.8301 - f1_score: 0.2624 - val_loss: 2.1768 - val_acc: 0.3240 - val_auc_2: 0.8036 - val_recall_2: 0.1530 - val_precision_2: 0.5716 - val_hamming_loss: 0.8470 - val_f1_score: 0.2287\n","Epoch 7/10\n","200/200 [==============================] - 11s 56ms/step - loss: 1.8810 - acc: 0.4077 - auc_2: 0.8517 - recall_2: 0.1955 - precision_2: 0.6997 - hamming_loss: 0.8045 - f1_score: 0.2970 - val_loss: 2.0255 - val_acc: 0.3737 - val_auc_2: 0.8312 - val_recall_2: 0.1817 - val_precision_2: 0.6022 - val_hamming_loss: 0.8183 - val_f1_score: 0.2610\n","Epoch 8/10\n","200/200 [==============================] - 11s 55ms/step - loss: 1.7989 - acc: 0.4302 - auc_2: 0.8655 - recall_2: 0.2188 - precision_2: 0.7156 - hamming_loss: 0.7812 - f1_score: 0.3259 - val_loss: 1.9069 - val_acc: 0.4133 - val_auc_2: 0.8497 - val_recall_2: 0.2110 - val_precision_2: 0.6433 - val_hamming_loss: 0.7890 - val_f1_score: 0.3005\n","Epoch 9/10\n","200/200 [==============================] - 11s 56ms/step - loss: 1.7319 - acc: 0.4530 - auc_2: 0.8765 - recall_2: 0.2404 - precision_2: 0.7293 - hamming_loss: 0.7596 - f1_score: 0.3527 - val_loss: 1.9576 - val_acc: 0.4017 - val_auc_2: 0.8441 - val_recall_2: 0.2287 - val_precision_2: 0.6305 - val_hamming_loss: 0.7713 - val_f1_score: 0.3060\n","Epoch 10/10\n","200/200 [==============================] - 11s 55ms/step - loss: 1.6530 - acc: 0.4771 - auc_2: 0.8882 - recall_2: 0.2695 - precision_2: 0.7528 - hamming_loss: 0.7305 - f1_score: 0.3875 - val_loss: 1.8429 - val_acc: 0.4450 - val_auc_2: 0.8612 - val_recall_2: 0.2450 - val_precision_2: 0.6927 - val_hamming_loss: 0.7550 - val_f1_score: 0.3475\n","94/94 [==============================] - 5s 28ms/step - loss: 1.8887 - acc: 0.4303 - auc_2: 0.8543 - recall_2: 0.2350 - precision_2: 0.6714 - hamming_loss: 0.7650 - f1_score: 0.3312\n","***********test accuracy is [1.8886909484863281, 0.43033334612846375, 0.854289710521698, 0.23499999940395355, 0.6714285612106323, 0.7649999856948853, array([0.16216215, 0.28458497, 0.28158844, 0.4829932 , 0.43181816,\n","       0.60115606, 0.35741445, 0.04830918, 0.2983051 , 0.2992126 ,\n","       0.3411371 , 0.55128205, 0.4074074 , 0.13698632, 0.28363636],\n","      dtype=float32)] ***************\n","***********train time is 115.7976531390002 ***************\n","f1 score is 0.3311995687584082\n"]}],"source":["print(\"*********** Fitting model for 256 dataset size and 4 hidden layers\")\n","model, cb = compile_model(256, 4)\n","model.fit(X_train, y_train, batch_size = 120, epochs=10, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"***********train time is\", sum(cb.logs),\"***************\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":155393,"status":"ok","timestamp":1648912036101,"user":{"displayName":"Imp Makers","userId":"16307378287047438992"},"user_tz":-330},"id":"mnYZs7Gswspg","outputId":"fa2c219f-b97d-4fa8-ca5a-db8ddf2a79bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 128 dataset size and 8 hidden layers\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 19s 68ms/step - loss: 2.7237 - acc: 0.1366 - auc_3: 0.6136 - recall_3: 0.0072 - precision_3: 0.3245 - hamming_loss: 0.9928 - f1_score: 0.0133 - val_loss: 2.5278 - val_acc: 0.1800 - val_auc_3: 0.6786 - val_recall_3: 0.0083 - val_precision_3: 0.5319 - val_hamming_loss: 0.9917 - val_f1_score: 0.0148\n","Epoch 2/10\n","200/200 [==============================] - 11s 56ms/step - loss: 2.4419 - acc: 0.2039 - auc_3: 0.7097 - recall_3: 0.0208 - precision_3: 0.6553 - hamming_loss: 0.9792 - f1_score: 0.0361 - val_loss: 2.4225 - val_acc: 0.2097 - val_auc_3: 0.7222 - val_recall_3: 0.0160 - val_precision_3: 0.5714 - val_hamming_loss: 0.9840 - val_f1_score: 0.0285\n","Epoch 3/10\n","200/200 [==============================] - 11s 57ms/step - loss: 2.3137 - acc: 0.2490 - auc_3: 0.7533 - recall_3: 0.0387 - precision_3: 0.6974 - hamming_loss: 0.9613 - f1_score: 0.0665 - val_loss: 2.3060 - val_acc: 0.2647 - val_auc_3: 0.7550 - val_recall_3: 0.0457 - val_precision_3: 0.6524 - val_hamming_loss: 0.9543 - val_f1_score: 0.0749\n","Epoch 4/10\n","200/200 [==============================] - 11s 57ms/step - loss: 2.2162 - acc: 0.2840 - auc_3: 0.7810 - recall_3: 0.0575 - precision_3: 0.7043 - hamming_loss: 0.9425 - f1_score: 0.0967 - val_loss: 2.2199 - val_acc: 0.2793 - val_auc_3: 0.7818 - val_recall_3: 0.0463 - val_precision_3: 0.7092 - val_hamming_loss: 0.9537 - val_f1_score: 0.0805\n","Epoch 5/10\n","200/200 [==============================] - 11s 56ms/step - loss: 2.1299 - acc: 0.3113 - auc_3: 0.8027 - recall_3: 0.0751 - precision_3: 0.7178 - hamming_loss: 0.9249 - f1_score: 0.1244 - val_loss: 2.2327 - val_acc: 0.2863 - val_auc_3: 0.7804 - val_recall_3: 0.0713 - val_precision_3: 0.6564 - val_hamming_loss: 0.9287 - val_f1_score: 0.1189\n","Epoch 6/10\n","200/200 [==============================] - 11s 57ms/step - loss: 2.0562 - acc: 0.3422 - auc_3: 0.8190 - recall_3: 0.0965 - precision_3: 0.7263 - hamming_loss: 0.9035 - f1_score: 0.1574 - val_loss: 2.0873 - val_acc: 0.3290 - val_auc_3: 0.8145 - val_recall_3: 0.1017 - val_precision_3: 0.6602 - val_hamming_loss: 0.8983 - val_f1_score: 0.1551\n","Epoch 7/10\n","200/200 [==============================] - 11s 56ms/step - loss: 1.9964 - acc: 0.3592 - auc_3: 0.8318 - recall_3: 0.1133 - precision_3: 0.7204 - hamming_loss: 0.8867 - f1_score: 0.1811 - val_loss: 2.0480 - val_acc: 0.3340 - val_auc_3: 0.8218 - val_recall_3: 0.1213 - val_precision_3: 0.6804 - val_hamming_loss: 0.8787 - val_f1_score: 0.1836\n","Epoch 8/10\n","200/200 [==============================] - 11s 57ms/step - loss: 1.9364 - acc: 0.3804 - auc_3: 0.8435 - recall_3: 0.1338 - precision_3: 0.7362 - hamming_loss: 0.8662 - f1_score: 0.2111 - val_loss: 2.0403 - val_acc: 0.3427 - val_auc_3: 0.8238 - val_recall_3: 0.0940 - val_precision_3: 0.7194 - val_hamming_loss: 0.9060 - val_f1_score: 0.1554\n","Epoch 9/10\n","200/200 [==============================] - 11s 56ms/step - loss: 1.8806 - acc: 0.3969 - auc_3: 0.8538 - recall_3: 0.1517 - precision_3: 0.7440 - hamming_loss: 0.8483 - f1_score: 0.2347 - val_loss: 2.0214 - val_acc: 0.3597 - val_auc_3: 0.8278 - val_recall_3: 0.1400 - val_precision_3: 0.6364 - val_hamming_loss: 0.8600 - val_f1_score: 0.2025\n","Epoch 10/10\n","200/200 [==============================] - 11s 57ms/step - loss: 1.8314 - acc: 0.4128 - auc_3: 0.8628 - recall_3: 0.1661 - precision_3: 0.7404 - hamming_loss: 0.8339 - f1_score: 0.2544 - val_loss: 1.9185 - val_acc: 0.3863 - val_auc_3: 0.8490 - val_recall_3: 0.1593 - val_precision_3: 0.6751 - val_hamming_loss: 0.8407 - val_f1_score: 0.2307\n","94/94 [==============================] - 5s 28ms/step - loss: 1.9443 - acc: 0.3770 - auc_3: 0.8428 - recall_3: 0.1590 - precision_3: 0.6543 - hamming_loss: 0.8410 - f1_score: 0.2329\n","***********test accuracy is [1.9443386793136597, 0.37700000405311584, 0.8428179621696472, 0.1589999943971634, 0.654321014881134, 0.8410000205039978, array([0.04830918, 0.18502201, 0.15789475, 0.38670692, 0.3140496 ,\n","       0.47468355, 0.28688523, 0.04761905, 0.0990991 , 0.3129771 ,\n","       0.0921659 , 0.45954692, 0.43661967, 0.05825243, 0.13392857],\n","      dtype=float32)] ***************\n","***********train time is 121.09053901099992 ***************\n","f1 score is 0.23291733240087828\n"]}],"source":["print(\"*********** Fitting model for 128 dataset size and 8 hidden layers\")\n","model, cb = compile_model(128, 8)\n","model.fit(X_train, y_train, batch_size = 120, epochs=10, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"***********train time is\", sum(cb.logs),\"***************\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":155469,"status":"ok","timestamp":1648912191562,"user":{"displayName":"Imp Makers","userId":"16307378287047438992"},"user_tz":-330},"id":"78fYhAv-xGbn","outputId":"3b975f27-d7e3-46ab-f05b-63f7828693b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 64 dataset size and 16 hidden layers\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 20s 67ms/step - loss: 2.6952 - acc: 0.0867 - auc_4: 0.5444 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.6684 - val_acc: 0.0987 - val_auc_4: 0.5885 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 2/10\n","200/200 [==============================] - 11s 57ms/step - loss: 2.6247 - acc: 0.1218 - auc_4: 0.6263 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.5792 - val_acc: 0.1500 - val_auc_4: 0.6556 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 3/10\n","200/200 [==============================] - 11s 56ms/step - loss: 2.5300 - acc: 0.1598 - auc_4: 0.6804 - recall_4: 4.5833e-04 - precision_4: 0.6111 - hamming_loss: 0.9995 - f1_score: 9.0651e-04 - val_loss: 2.4726 - val_acc: 0.1853 - val_auc_4: 0.7087 - val_recall_4: 0.0013 - val_precision_4: 0.4000 - val_hamming_loss: 0.9987 - val_f1_score: 0.0025\n","Epoch 4/10\n","200/200 [==============================] - 11s 56ms/step - loss: 2.4534 - acc: 0.1821 - auc_4: 0.7114 - recall_4: 0.0032 - precision_4: 0.4780 - hamming_loss: 0.9968 - f1_score: 0.0059 - val_loss: 2.4102 - val_acc: 0.1977 - val_auc_4: 0.7272 - val_recall_4: 0.0030 - val_precision_4: 0.6429 - val_hamming_loss: 0.9970 - val_f1_score: 0.0059\n","Epoch 5/10\n","200/200 [==============================] - 11s 57ms/step - loss: 2.3921 - acc: 0.2022 - auc_4: 0.7333 - recall_4: 0.0095 - precision_4: 0.5718 - hamming_loss: 0.9905 - f1_score: 0.0168 - val_loss: 2.3872 - val_acc: 0.2023 - val_auc_4: 0.7344 - val_recall_4: 0.0087 - val_precision_4: 0.5098 - val_hamming_loss: 0.9913 - val_f1_score: 0.0154\n","Epoch 6/10\n","200/200 [==============================] - 11s 57ms/step - loss: 2.3399 - acc: 0.2142 - auc_4: 0.7500 - recall_4: 0.0178 - precision_4: 0.6121 - hamming_loss: 0.9822 - f1_score: 0.0308 - val_loss: 2.3037 - val_acc: 0.2227 - val_auc_4: 0.7618 - val_recall_4: 0.0173 - val_precision_4: 0.5591 - val_hamming_loss: 0.9827 - val_f1_score: 0.0290\n","Epoch 7/10\n","200/200 [==============================] - 12s 58ms/step - loss: 2.3007 - acc: 0.2272 - auc_4: 0.7620 - recall_4: 0.0252 - precision_4: 0.6176 - hamming_loss: 0.9748 - f1_score: 0.0421 - val_loss: 2.2848 - val_acc: 0.2380 - val_auc_4: 0.7671 - val_recall_4: 0.0280 - val_precision_4: 0.6462 - val_hamming_loss: 0.9720 - val_f1_score: 0.0458\n","Epoch 8/10\n","200/200 [==============================] - 11s 57ms/step - loss: 2.2621 - acc: 0.2393 - auc_4: 0.7731 - recall_4: 0.0322 - precision_4: 0.6570 - hamming_loss: 0.9678 - f1_score: 0.0540 - val_loss: 2.2313 - val_acc: 0.2523 - val_auc_4: 0.7818 - val_recall_4: 0.0340 - val_precision_4: 0.6800 - val_hamming_loss: 0.9660 - val_f1_score: 0.0567\n","Epoch 9/10\n","200/200 [==============================] - 11s 57ms/step - loss: 2.2368 - acc: 0.2481 - auc_4: 0.7793 - recall_4: 0.0382 - precision_4: 0.6693 - hamming_loss: 0.9618 - f1_score: 0.0633 - val_loss: 2.3439 - val_acc: 0.2293 - val_auc_4: 0.7554 - val_recall_4: 0.0373 - val_precision_4: 0.5283 - val_hamming_loss: 0.9627 - val_f1_score: 0.0567\n","Epoch 10/10\n","200/200 [==============================] - 11s 57ms/step - loss: 2.2094 - acc: 0.2607 - auc_4: 0.7864 - recall_4: 0.0436 - precision_4: 0.6757 - hamming_loss: 0.9564 - f1_score: 0.0718 - val_loss: 2.1880 - val_acc: 0.2590 - val_auc_4: 0.7930 - val_recall_4: 0.0497 - val_precision_4: 0.6314 - val_hamming_loss: 0.9503 - val_f1_score: 0.0751\n","94/94 [==============================] - 4s 28ms/step - loss: 2.2196 - acc: 0.2560 - auc_4: 0.7864 - recall_4: 0.0523 - precision_4: 0.6515 - hamming_loss: 0.9477 - f1_score: 0.0801\n","***********test accuracy is [2.219611406326294, 0.25600001215934753, 0.7863819003105164, 0.05233333259820938, 0.6514523029327393, 0.9476666450500488, array([0.        , 0.        , 0.01970443, 0.11818181, 0.08571429,\n","       0.3838384 , 0.19298245, 0.        , 0.        , 0.        ,\n","       0.        , 0.35251796, 0.04878049, 0.        , 0.        ],\n","      dtype=float32)] ***************\n","***********train time is 122.97838168899943 ***************\n","f1 score is 0.080114654575785\n"]}],"source":["print(\"*********** Fitting model for 64 dataset size and 16 hidden layers\")\n","model, cb = compile_model(64, 16)\n","model.fit(X_train, y_train, batch_size = 120, epochs=10, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"***********train time is\", sum(cb.logs),\"***************\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":137425,"status":"ok","timestamp":1648912328982,"user":{"displayName":"Imp Makers","userId":"16307378287047438992"},"user_tz":-330},"id":"A9FsF6glxcsR","outputId":"30d13b82-6487-42c4-8789-d4571810a99e"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 32 dataset size and 32 hidden layers\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 24s 76ms/step - loss: 2.7058 - acc: 0.0817 - auc_5: 0.5100 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.7011 - val_acc: 0.0880 - val_auc_5: 0.5222 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 2/10\n","200/200 [==============================] - 12s 59ms/step - loss: 2.6896 - acc: 0.1020 - auc_5: 0.5529 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.6802 - val_acc: 0.1057 - val_auc_5: 0.5779 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 3/10\n","200/200 [==============================] - 12s 59ms/step - loss: 2.6636 - acc: 0.1072 - auc_5: 0.5962 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.6529 - val_acc: 0.1030 - val_auc_5: 0.6033 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 4/10\n","200/200 [==============================] - 12s 59ms/step - loss: 2.6329 - acc: 0.1098 - auc_5: 0.6228 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.6136 - val_acc: 0.1100 - val_auc_5: 0.6343 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 5/10\n","200/200 [==============================] - 12s 58ms/step - loss: 2.5946 - acc: 0.1120 - auc_5: 0.6454 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.5740 - val_acc: 0.1087 - val_auc_5: 0.6543 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 6/10\n","200/200 [==============================] - 12s 59ms/step - loss: 2.5537 - acc: 0.1138 - auc_5: 0.6641 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.5309 - val_acc: 0.1163 - val_auc_5: 0.6760 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 7/10\n","200/200 [==============================] - 12s 59ms/step - loss: 2.5187 - acc: 0.1190 - auc_5: 0.6790 - recall_5: 8.3333e-04 - precision_5: 0.8000 - hamming_loss: 0.9992 - f1_score: 0.0016 - val_loss: 2.5608 - val_acc: 0.1057 - val_auc_5: 0.6544 - val_recall_5: 0.0013 - val_precision_5: 1.0000 - val_hamming_loss: 0.9987 - val_f1_score: 0.0026\n","Epoch 8/10\n","200/200 [==============================] - 12s 59ms/step - loss: 2.4929 - acc: 0.1241 - auc_5: 0.6905 - recall_5: 0.0026 - precision_5: 0.6458 - hamming_loss: 0.9974 - f1_score: 0.0048 - val_loss: 2.4752 - val_acc: 0.1223 - val_auc_5: 0.6989 - val_recall_5: 0.0070 - val_precision_5: 0.5385 - val_hamming_loss: 0.9930 - val_f1_score: 0.0116\n","Epoch 9/10\n","200/200 [==============================] - 12s 59ms/step - loss: 2.4723 - acc: 0.1321 - auc_5: 0.6997 - recall_5: 0.0058 - precision_5: 0.6053 - hamming_loss: 0.9942 - f1_score: 0.0100 - val_loss: 2.4572 - val_acc: 0.1310 - val_auc_5: 0.7055 - val_recall_5: 0.0057 - val_precision_5: 0.6296 - val_hamming_loss: 0.9943 - val_f1_score: 0.0099\n","Epoch 10/10\n","200/200 [==============================] - 12s 59ms/step - loss: 2.4543 - acc: 0.1293 - auc_5: 0.7063 - recall_5: 0.0077 - precision_5: 0.5993 - hamming_loss: 0.9923 - f1_score: 0.0128 - val_loss: 2.4327 - val_acc: 0.1370 - val_auc_5: 0.7153 - val_recall_5: 0.0093 - val_precision_5: 0.5833 - val_hamming_loss: 0.9907 - val_f1_score: 0.0149\n","94/94 [==============================] - 5s 28ms/step - loss: 2.4371 - acc: 0.1397 - auc_5: 0.7133 - recall_5: 0.0067 - precision_5: 0.5405 - hamming_loss: 0.9933 - f1_score: 0.0112\n","***********test accuracy is [2.437140941619873, 0.13966666162014008, 0.7132554650306702, 0.006666666828095913, 0.5405405163764954, 0.9933333396911621, array([0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n","       0.      , 0.      , 0.      , 0.      , 0.      , 0.167364,\n","       0.      , 0.      , 0.      ], dtype=float32)] ***************\n","***********train time is 129.28221560800012 ***************\n","f1 score is 0.011157600084940593\n"]}],"source":["print(\"*********** Fitting model for 32 dataset size and 32 hidden layers\")\n","model, cb = compile_model(32, 32)\n","model.fit(X_train, y_train, batch_size = 120, epochs=10, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"***********train time is\", sum(cb.logs),\"***************\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":150489,"status":"ok","timestamp":1648912877649,"user":{"displayName":"Imp Makers","userId":"16307378287047438992"},"user_tz":-330},"id":"GA7THSTWyCM_","outputId":"4c7fed61-540d-4184-dbaa-413d7261f1e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Fitting model for 16 dataset size and 64 hidden layers\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 27s 75ms/step - loss: 2.7081 - acc: 0.0642 - auc_7: 0.5000 - recall_7: 0.0000e+00 - precision_7: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.7080 - val_acc: 0.0673 - val_auc_7: 0.5000 - val_recall_7: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 2/10\n","200/200 [==============================] - 12s 61ms/step - loss: 2.7081 - acc: 0.0644 - auc_7: 0.5000 - recall_7: 0.0000e+00 - precision_7: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.7080 - val_acc: 0.0673 - val_auc_7: 0.5000 - val_recall_7: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 3/10\n","200/200 [==============================] - 12s 61ms/step - loss: 2.7081 - acc: 0.0635 - auc_7: 0.5000 - recall_7: 0.0000e+00 - precision_7: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.7080 - val_acc: 0.0673 - val_auc_7: 0.5000 - val_recall_7: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 4/10\n","200/200 [==============================] - 13s 63ms/step - loss: 2.7081 - acc: 0.0667 - auc_7: 0.5000 - recall_7: 0.0000e+00 - precision_7: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.7080 - val_acc: 0.0673 - val_auc_7: 0.5000 - val_recall_7: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 5/10\n","200/200 [==============================] - 13s 63ms/step - loss: 2.7081 - acc: 0.0666 - auc_7: 0.5000 - recall_7: 0.0000e+00 - precision_7: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.7080 - val_acc: 0.0673 - val_auc_7: 0.5000 - val_recall_7: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 6/10\n","200/200 [==============================] - 13s 64ms/step - loss: 2.7081 - acc: 0.0671 - auc_7: 0.5000 - recall_7: 0.0000e+00 - precision_7: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.7080 - val_acc: 0.0673 - val_auc_7: 0.5000 - val_recall_7: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 7/10\n","200/200 [==============================] - 13s 63ms/step - loss: 2.7081 - acc: 0.0673 - auc_7: 0.5000 - recall_7: 0.0000e+00 - precision_7: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.7080 - val_acc: 0.0673 - val_auc_7: 0.5000 - val_recall_7: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 8/10\n","200/200 [==============================] - 13s 63ms/step - loss: 2.7081 - acc: 0.0673 - auc_7: 0.5000 - recall_7: 0.0000e+00 - precision_7: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.7080 - val_acc: 0.0673 - val_auc_7: 0.5000 - val_recall_7: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 9/10\n","200/200 [==============================] - 13s 63ms/step - loss: 2.7081 - acc: 0.0666 - auc_7: 0.5000 - recall_7: 0.0000e+00 - precision_7: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.7080 - val_acc: 0.0673 - val_auc_7: 0.5000 - val_recall_7: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","Epoch 10/10\n","200/200 [==============================] - 13s 63ms/step - loss: 2.7081 - acc: 0.0660 - auc_7: 0.5000 - recall_7: 0.0000e+00 - precision_7: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00 - val_loss: 2.7080 - val_acc: 0.0673 - val_auc_7: 0.5000 - val_recall_7: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_hamming_loss: 1.0000 - val_f1_score: 0.0000e+00\n","94/94 [==============================] - 5s 30ms/step - loss: 2.7080 - acc: 0.0673 - auc_7: 0.5000 - recall_7: 0.0000e+00 - precision_7: 0.0000e+00 - hamming_loss: 1.0000 - f1_score: 0.0000e+00\n","***********test accuracy is [2.708041191101074, 0.06733333319425583, 0.5, 0.0, 0.0, 1.0, array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","      dtype=float32)] ***************\n","***********train time is 139.30049758900032 ***************\n","f1 score is 0.0\n"]}],"source":["print(\"*********** Fitting model for 16 dataset size and 64 hidden layers\")\n","model, cb = compile_model(16, 64)\n","model.fit(X_train, y_train, batch_size = 120, epochs=10, validation_data=(X_val, y_val), callbacks = [cb])\n","test_acc = model.evaluate(X_test, y_test)\n","print(\"***********test accuracy is\", test_acc,\"***************\")\n","print(\"***********train time is\", sum(cb.logs),\"***************\")\n","print(\"f1 score is\", sum(test_acc[6])/15)"]}]}